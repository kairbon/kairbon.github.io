<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kairbon&#39;s Blog</title>
  
  
  <link href="https://kairbon.github.io/atom.xml" rel="self"/>
  
  <link href="https://kairbon.github.io/"/>
  <updated>2022-02-10T15:08:35.125Z</updated>
  <id>https://kairbon.github.io/</id>
  
  <author>
    <name>Kairbon</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>思考自己能做到的（3）这段时间的反思</title>
    <link href="https://kairbon.github.io/2022/02/10/%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E8%83%BD%E5%81%9A%E5%88%B0%E7%9A%843/"/>
    <id>https://kairbon.github.io/2022/02/10/%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E8%83%BD%E5%81%9A%E5%88%B0%E7%9A%843/</id>
    <published>2022-02-10T21:58:00.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="这段时间的反思"><a href="#这段时间的反思" class="headerlink" title="这段时间的反思"></a>这段时间的反思</h2><p>简单总结一下自己这段时间（两个月）的成果和错误。</p><h3 id="成果"><a href="#成果" class="headerlink" title="成果"></a>成果</h3><h4 id="工作上："><a href="#工作上：" class="headerlink" title="工作上："></a>工作上：</h4><p>工作上最近其实算不错，我做了一些有意义的工作，取得了一些成绩。但是拿什么来衡量自己的成绩有没有对我好呢？我其实一直都觉得就是自己的晋升和奖金。但我才入职七个月，按照规定也没办法升职，奖金的话也没办法，今年公司的整体盈利不佳是现状，因此绩效我没有很高的预期。不过好的点是自己能在工作中找到乐趣所在。</p><ol><li>拿了一篇专利。</li><li>发了一篇ATA。</li><li>完结了三个中等需求。</li><li>有一个技术先进性的项目。</li></ol><h4 id="生活上："><a href="#生活上：" class="headerlink" title="生活上："></a>生活上：</h4><p>其实出社会了的生活我远没有我之前想象的那样有趣，就只是一个人呆在房子里，杭州的话也没怎么转过。社交圈仅限于学生时候认识的和工作时候认识的，自己没有主动去社交过。谈了快一年的女友和我也分手了。总体来说很难受，但还是有一些优点可以挖掘出来的。</p><ol><li>养成了记账的习惯。坚持了三个月了。</li><li>有空会编曲，偶尔能沉浸在音乐中。</li><li>自己的个人卫生习惯有很大的改善，自己可以每天整理房子，衣服叠整齐。</li></ol><h3 id="不足点："><a href="#不足点：" class="headerlink" title="不足点："></a>不足点：</h3><h4 id="工作上：-1"><a href="#工作上：-1" class="headerlink" title="工作上："></a>工作上：</h4><p>工作上的不足点其实不少，包括：</p><ol><li>自己的代码不能完全的bug free，有时候一个大一点的项目编写的过程中会容易出错。</li><li>自己有时候容易激动，想到了一个好点子就过于开心。</li><li>工作压力大的时候偶尔会忍不住焦虑。</li><li>项目管理能力不够成熟。</li><li>代码能力有待加强。</li></ol><h4 id="生活上：-1"><a href="#生活上：-1" class="headerlink" title="生活上："></a>生活上：</h4><ol><li>个人卫生问题还是不够好，每天洗澡和睡前刷牙还是有时候就不能做到。</li><li>情绪下意识就会emo。</li><li>情绪激动时候缺少换位思考。</li><li>情绪激动的时候就只想着眼前的一步该怎么走。</li></ol><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>目前来看，不足之处主要集中于情绪不稳定，容易过于开心，悲伤或焦虑。接下来要学会控制自己的情绪。下一个周期是三月份，到时候希望能够看到自己的改变</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;这段时间的反思&quot;&gt;&lt;a href=&quot;#这段时间的反思&quot; class=&quot;headerlink&quot; title=&quot;这段时间的反思&quot;&gt;&lt;/a&gt;这段时间的反思&lt;/h2&gt;&lt;p&gt;简单总结一下自己这段时间（两个月）的成果和错误。&lt;/p&gt;
&lt;h3 id=&quot;成果&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="随笔系列" scheme="https://kairbon.github.io/categories/%E9%9A%8F%E7%AC%94%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="这就是生活" scheme="https://kairbon.github.io/tags/%E8%BF%99%E5%B0%B1%E6%98%AF%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>数据集成场景优化——任务编排/限流</title>
    <link href="https://kairbon.github.io/2021/12/08/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%9C%BA%E6%99%AF%E4%BC%98%E5%8C%96/"/>
    <id>https://kairbon.github.io/2021/12/08/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%9C%BA%E6%99%AF%E4%BC%98%E5%8C%96/</id>
    <published>2021-12-08T10:00:41.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据集成场景优化——任务编排-限流"><a href="#数据集成场景优化——任务编排-限流" class="headerlink" title="数据集成场景优化——任务编排/限流"></a>数据集成场景优化——任务编排/限流</h1><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p>Disruptor:</p><p>「资料1」建议入门直接看这一个博客深入Disruptor原理： <a href="https://ifeve.com/disruptor/">https://ifeve.com/disruptor/</a> </p><p>「资料2」这一篇也非常推荐，应用实例： <a href="https://tech.meituan.com/2016/11/18/disruptor.html">https://tech.meituan.com/2016/11/18/disruptor.html</a></p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><p>我们有一个2B的SaaS应用，每个租户下有几万十几万不等的「Item」，我们有一个每天每个租户下都会有上千万次以「itemId」作为参数，来查询这个「Item」需要在查询方应用中该怎么处理的接口。</p><p>为了减轻调用方的调用负担，这个接口的入参只是「ItemId」。但在我们接口内部我们会根据「ItemId」拉取能够通过「ItemId」获取到的所有的数据作为实际我们处理过程中所用到信息。举个例子：</p><p><img src="/images/2021-12-07-13-21-29.png" alt="图一，一个例子"></p><ol><li>调用方使用itemID作为入参请求我们的接口。</li><li>程序内部通过一连串的请求来拉取使用ItemId可以获取到的参数。<br> a. 通过itemId获取storeCode的list。<br> b. 通过storeCode获取StoreInfo。<br> c. 通过storeCode获取StoreType.</li><li>合并参数并且将参数交给后面的算法处理。</li><li>结果返回给调用方。</li></ol><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>上述的场景其实是一个颇为平常的业务Service的代码流程，不过如果应用在我们的应用中将会遇到了一些问题：</p><p>一、RT较高（目标15ms以下）：</p><ol><li>业务请求我们接口，我们的调用ServiceA,B,C 因为都是RPC访问，因此我们接口的整体RT取决于ServiceA，B，C的延迟。尤其是我们的接口调用都集中在某些特定的时间。</li><li>我们调用其他的接口采用同步阻塞调用的方式，对于整体的IO来说其实没有充分利用计算资源。</li></ol><p>二、下游扛不住：</p><ol><li>因为有某些时刻集会中调用我们的接口，qps非常高。但是Service A,B,C并不能承诺我们这么高的qps。</li></ol><p>三、数据集成的复杂性：<br><img src="/images/2021-12-08-17-52-07.png" alt="图二、数据依赖"></p><ol><li>任务有依赖关系：比如 Service B和 Service C可以并行，但是他们都依赖于Service A执行完成。如上图。</li><li>多租户：对于每一个我们应用的租户，都会有自己需要访问的Service D E F和不同的依赖关系。</li><li>我们依赖的服务全部都是同步接口，采用全异步的编程当然能解决很多问题，但是全域的改造则需要有充足的资源。</li></ol><h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>首先简单分析一下场景：因为我们应用的客户接入的数据源（也就是Service A，B，C）一般是主数据相关，变化不怎么频繁，通常T-1的时效即可，因此我们大多数情况下可以直接使用离线数据。但是有时候，有些数据源的时效性要求又比较高，比如分钟级别，或直接就必须要实时。因此我们必须要分类处理。将数据源区分为准实时，离线，和实时。</p><p>「离线数据」：目前并没有这样的一个数据中间层。因此我们需要使用一个定时运行的离线任务，提前将当前租户下所有itemId能够关联的数据都保存一遍。类似下图所示：</p><p><img src="/images/2021-12-07-09-36-08.png" alt="图三，应用主流程"></p><p>「准实时」：准实时的实现有多种，比如让租户统一告诉我们哪些itemId关联的数据发生了变化。我们再启动离线任务去对这些itemId所关联的信息做异步的更新。</p><p>「实时」：如果对一致性要求非常严格，那么我们需要支持实时去访问。</p><p>区分数据源要求的时效性的好处显而易见，对于因为离线数据和准实时场景都是去查数据库，而查数据库的延迟和并发就宽松多了。必须实时那部分数据源因为占比的少，因此对平均RT影响不大。当然这只是从性能角度出发，从人效的角度讲，对后续数据源的接入需求来说通过这样的方式能让我们更快定位场景从而更快形成解决方案。</p><p>那么一个离线任务如何构建呢？首先这个离线任务执行的快，以达到准实时，那就得并发和非阻塞IO，而且还得考虑数据源之间依赖的问题，那就得想用什么样的数据结构去承载任务？以上述的Service A，B，C我们可以轻松的想到我们可以像运行一个树一样运行，只要中序遍历就好了。 但是现实情况是同一个服务可能有多个依赖。如下图，Service C 依赖 Service A，D。</p><p><img src="%C3%9F/images/2021-12-08-17-57-07.png" alt="图四、拓扑结构"></p><p>因此我们其实可以想到最合适的其实是拓扑结构。那么拓扑结构怎么去执行呢？这就需要一个能够支持拓扑任务运行的工具。综合上述的需求，我们采用了Disruptor作为我们的单机任务分发框架。</p><h5 id="Disruptor"><a href="#Disruptor" class="headerlink" title="Disruptor"></a>Disruptor</h5><p>Disrupoter是一个高性能任务分发框架，本次使用这个框架主要是为了弥补我们正在使用的任务分发框架ScheduleX弹内版不便于处理单机编排流程。我们主要采用了disruptor的after操作来构建拓扑，从而满足我们对io请求先后顺序和并行请求的两个需求（也就是拓扑结构任务的运行）。</p><p>Disruptor的整体结构如下：是一个相对简单的机制。<br><img src="/images/2021-12-11-13-04-29.png" alt="图五、disrputor"></p><p>对于我们来说，每个数据源（Service）就一个处理节点。对于树状结构没办法解决的菱形结构如下图：<br><img src="/images/2021-12-11-13-12-35.png" alt="图六、菱形结构"></p><p>通过ConsumerBarrier 和 处理节点的组合就可以解决这个问题。<br><img src="/images/2021-12-11-13-13-11.png" alt="图七、结构"></p><p>其实上述只是举了个小例子说明disruptor的实现，当然这里有个小细节更能让大家感受到disruptor对各种情况处理的思考。就是disruptor如何实现处理节点的等待（依赖前面的执行结束）。我这里还是举一个官网的例子如下图，详情大家可以自己去研究。</p><p><img src="/images/2021-12-11-13-17-46.png" alt="图八、消费者等待1"><br>生产者 P1 已经在 Ring Buffer 里写到序号 22 了，消费者 C1 已经访问和处理完了序号 21 之前的所有数据。消费者 C2 处理到了序号 18。消费者 C3，就是依赖其他消费者的那个，才处理到序号 15。生产者 P1 不能继续向 RingBuffer 写入数据了，因为序号 15 占据了我们想要写入序号 23 的数据节点 (Slot)。</p><p><img src="/images/2021-12-11-13-20-11.png" alt="图九、消费者等待2"></p><p>第一个 ConsumerBarrier（CB1）告诉 C1 和 C2 消费者可以去访问序号 22 前面的所有数据，这是 Ring Buffer 中的最大序号。第二个 ConsumerBarrier (CB2) 不但会检查 RingBuffer 的序号，也会检查另外C1和C2已经消费过的序号并且返回它们之间的最小值。因此，三号消费者被告知可以访问 Ring Buffer 里序号 18 前面的数据。</p><p>注意这些消费者还是直接从 Ring Buffer 拿数据节点——并不是由 C1 和 C2 消费者把数据节点从 Ring Buffer 里取出再传递给 C3 消费者的。作为替代的是，由第二个 ConsumerBarrier 告诉 C3 消费者，在 RingBuffer 里的哪些节点可以安全的处理。这样的处理能够最大程度减少复制的成本和减少无意义的CPU使用率。</p><p>这产生了一个技术性的问题——如果任何数据都来自于 Ring Buffer，那么 C3 消费者如何读到c1, c2处理完成的数据呢？如果 C3 消费者关心的只是先前的消费者是否已经完成它们的工作（例如，把数据复制到别的地方），那么这一切都没有问题—— C3 消费者知道工作已完成就放心了。但是，如果 C3 消费者需要访问先前的消费者的处理结果，它又从哪里去获取呢？</p><p>秘密在于把处理结果写入 Ring Buffer 数据节点 (Entry) 本身。这样，当 C3 消费者从 Ring Buffer 取出节点时，它已经填充好了 C3 消费者工作需要的所有信息。这里 真正 重要的地方是节点 (Entry) 对象的每一个字段应该只允许一个消费者写入。这可以避免产生并发写入冲突 (write-contention) 减慢了整个处理过程。</p><p><img src="/images/2021-12-11-13-33-19.png" alt="图十、消费者写入冲突"></p><p>你可以在 DiamondPath1P3CPerfTest​:</p><p><a href="http://code.google.com/p/disruptor/source/browse/trunk/code/src/perf/com/lmax/disruptor/DiamondPath1P3CPerfTest.java">http://code.google.com/p/disruptor/source/browse/trunk/code/src/perf/com/lmax/disruptor/DiamondPath1P3CPerfTest.java</a> </p><p>里看到这个例子—— FizzBuzzEntry​ 有两个字段：fizz 和 buzz。如果消费者是 Fizz Consumer, 它只写入字段 fizz。如果是 Buzz Consumer, 它只写入字段 buzz。第三个消费者 FizzBuzz，它只去读这两个字段但是不会做写入，因为读没问题，不会引起争用。</p><p>这个看起来很复杂，是的，它涉及到更多的内部协调。但是实际上代码实现上很简单，这一切看起来都要比队列实现更复杂。但是这些细节对于我们构建处理node是隐藏的，它们只和 Barrier 对象交互。诀窍在消费者结构里。上文例子中提到的菱形结构可以用下面的方法创建（show code！）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ConsumerBarrier consumerBarrier1 =</span><br><span class="line">    ringBuffer.createConsumerBarrier();</span><br><span class="line">BatchConsumer consumer1 =</span><br><span class="line">    <span class="keyword">new</span> BatchConsumer(consumerBarrier1, handler1);</span><br><span class="line">BatchConsumer consumer2 =</span><br><span class="line">    <span class="keyword">new</span> BatchConsumer(consumerBarrier1, handler2);</span><br><span class="line">ConsumerBarrier consumerBarrier2 =</span><br><span class="line">    ringBuffer.createConsumerBarrier(consumer1, consumer2);</span><br><span class="line">BatchConsumer consumer3 =</span><br><span class="line">    <span class="keyword">new</span> BatchConsumer(consumerBarrier2, handler3);</span><br><span class="line">ProducerBarrier producerBarrier =</span><br><span class="line">    ringBuffer.createProducerBarrier(consumer3);</span><br></pre></td></tr></table></figure><p>节点流程编排好了之后只需要实现消费者的代码即可。对于我们的SaaS场景也只需要为不同的租户创建不同的编排流程，当然我们做的更进一步，我们使用了可视配置的方式去直接选择依赖数据源。用户无需感知流程的编排过程，只需要写一个实现引入数据源即可。如下图：</p><hr><h5 id="限制服务请求流量："><a href="#限制服务请求流量：" class="headerlink" title="限制服务请求流量："></a>限制服务请求流量：</h5><p>前面我们提到过，我们除了考虑我们的性能之外，还得考虑别人能不能扛得住？也就是限制QPS，这里我们采用了令牌桶算法来针对每一个接入的数据源进行限流，（限制一个节点每秒能够处理的任务数量）。这个原理非常简单就不过多赘述，但是这里也会出现一个问题：</p><p><img src="/images/2021-12-11-14-01-20.png" alt="图十二、限流"></p><p>当B节点的QPS成为瓶颈时，其实后面的E和D即使QPS性能更好也无法尽可能充分利用资源。因此这种情况下可能需要对B的性能针对性的进行处理。处理方式很多，根据你的时效一致性来做就行，比如最常用的就是加一个缓存！</p><h5 id="离线任务"><a href="#离线任务" class="headerlink" title="离线任务"></a>离线任务</h5><p>因为拓扑图的构建对于不同租户来说是不一样的且繁琐的，因此我们需要一种方式去简化这一步。根据传统的离散数学中图论的知识我们知道每一个节点只需要知道他的上一步必须要经过的节点是什么就行了，所以我们就可以复用我们之前接入数据源的流程，只需要在每个节点的配置过程中多加一项上游数据源即可。这样我们对于每个租户就得到了一个数据源的列表，内含每个数据源依赖的数据源。（当然这里我们也需要对回环等问题进行校验）。</p><p>那么我们怎么把这个列表和disruptor结合起来变成一个运行态的拓扑任务呢？请见如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 处理有上游依赖的节点</span></span><br><span class="line"><span class="comment">// 当所有节点还没处理完就继续循环</span></span><br><span class="line"><span class="keyword">while</span> (processedSet.size() &lt; nodes.size()) &#123;</span><br><span class="line">    <span class="keyword">int</span> processedCnt = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, Node&gt; entry : hasDependencyNodeMap.entrySet()) &#123;</span><br><span class="line">        String k = entry.getKey();</span><br><span class="line">        Node v = entry.getValue();</span><br><span class="line">        <span class="comment">//过滤已处理节点</span></span><br><span class="line">        <span class="keyword">if</span> (processedSet.contains(k)) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果当前节点的所有上游依赖都已处理，否则继续循环</span></span><br><span class="line">        <span class="keyword">if</span> (!processedSet.containsAll(v.getDependencyBundleIdList())) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//构建依赖关系</span></span><br><span class="line">        StrategyDimensionPoolHandler[] preHandles = getHandlerArray(poolHandlerMap,</span><br><span class="line">            v.getDependencyBundleIdList());</span><br><span class="line">        StrategyDimensionPoolHandler currentHandler = poolHandlerMap.get(v.bundleId);</span><br><span class="line">        disruptor.after(preHandles).handleEventsWith(currentHandler);</span><br><span class="line">        <span class="comment">//计数及标记已处理bundleId</span></span><br><span class="line">        processedCnt++;</span><br><span class="line">        processedSet.add(k);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (processedCnt == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//存在循环依赖,跳出流程抛错</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然可能结合图会更好理解：</p><p><img src="/images/2021-12-11-17-27-33.png" alt="图十三、菱形结构"></p><p>开始我们已处理了一个没有任何依赖的节点A作为我们的开始节点之一。</p><p>第一次循环我们就可以处理两个有依赖的节点B和C。因为A已经被处理了</p><p><img src="/images/2021-12-11-17-30-02.png" alt="图十四、第一次循环"></p><p>第一次循环中，我们通过循环所有节点，如果当前的节点的依赖的节点都被计算过了，就将其加入后置的处理之中，构建出来的代码就是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">disruptor.after(A 「processedSet」 ).handle(B 「currentHandler」)。</span><br><span class="line">disruptor.after(A 「processedSet」 ).handle(C 「currentHandler」)。</span><br></pre></td></tr></table></figure><p>而第二次循环则将D节点最终处理掉了</p><p><img src="/images/2021-12-11-17-40-38.png" alt="图十五、第二次循环"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disruptor.after(A, B, C 「processedSet」 ).handle(B 「currentHandler」)。</span><br></pre></td></tr></table></figure><p>最终进行disruptor的start即可。</p><h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>过程中其实我们也是经历了多次讨论，尤其是对于数据的模型。</p><p>在数据源中，有一种数据源，是将一份数据 拆成多条数据，就是通过Itemid来查StoreCode。而拿到的ItemId+StoreCode又需要通过一些其他的非批量的节点来处理。如下图：</p><p><img src="/images/2021-12-11-18-24-55.png" alt="图十六、一维转二维"></p><p>这时候我们对于node的抽象就会出现问题，因为ServiceB不支持批量，因此我们就只能让他循环处理，但是ServiceA却不能，那么我们怎么解决这个问题呢？</p><p>我首先对数据定标准，首先对数据来说，我们观测的视角就是数据对维度，比如我们以ItemId的视角去观测数据，得到了一种维度的数据，以StoreCode的视角去观测数据，得到了一种维度的数据，这种我统一把它叫做一维数据。但是这个时候如果我需要ItemId+Store的数据，那么数据的观测维度变成了两个，就叫他二维数据。而维度数据源就是那种对将一维数据转化二维数据的数据源。</p><p>其次是数据维度拆分：在我们的概念里面，将数据源分类，分为「维度数据源」，和「维度辅助数据源」。</p><p>从实现角度讲维度数据源专门用来将一份数据从一个变成多个，可以理解为从单一视角变成了两个视角，而维度辅助数据源则保持原有维度不变，只是新增了一些同纬度的观测信息，可以理解为看数据的视角变广了，比如通过ItemId拿到ItemInfo的数据源。</p><p>在这个前提下我们将Node的实现变为了两种，对这两种Node做不同的编排处理以达到目标。</p><h4 id="灰度和对账"><a href="#灰度和对账" class="headerlink" title="灰度和对账"></a>灰度和对账</h4><p>灰度我们主要采用diamond灰度开关来去做整体的把控。这部分大家都比较常用，核心讲讲我们对账的经验：</p><p>我们还是采用线上的版本和新版本跑出来的结果表来作为对照查看数据是否一致，拓扑任务版本采用了Lindorm+Holo的持久层（这是另一part事，可能可能需要单独开个文章讲hh）天然和odps结合的很好，因此我们利用odps的回流离线表的方式，将线上版本的结果和拓扑版本的结果导入ODPS，再利用MAC数据对账平台<a href="https://mac.alibaba-inc.com/odps/">https://mac.alibaba-inc.com/odps/</a> 提供的对账功能花费不到半个人日就完成了对账操作。发现我们的新旧版本的结果数据差异率不到1%，有差别的主要是一些Item的关联信息发生变动。</p><hr><p>因此我们认为符合上线标准，准予上线。目前已经切了两个主要行业的租户。线上运行了快半个月了。</p><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>最终我们的架构图如下所示：</p><p><img src="/images/2021-12-12-11-38-40.png" alt="图十八、结果"></p><p>我用绿色B和红色A表示不同的流程：</p><p>B流程：正常用户的请求路径，用户的请求除了一些「实时数据源」需要走RPC调用，其余都直接进行查库处理。</p><p>A流程：离线任务的主流程，我们会在出解决方案的时候设计日数据版本的概念，一般一个租户一天会运行2到3次。对于「离线数据源」我们无需租户做额外配置。但是对于「准实时数据源」来说，我们会要求租户提供一个能够让我们感知到哪些数据发生了变化的方式。比如MQ消息或调用我们的提供的数据更新接口。</p><p>对于行业开发来说，在使用策略开放平台时，在「数据集成阶段」中只需要关心的就是引入一个符合规范的数据源。并且加上简单的配置：</p><hr><p>ps：这里加一个小细节，如何将集群的限流转换成对单机数据源的限流呢？<br>首先我们在出解决方案的时候会预估你需要的机器的数量。<br>然后会将你配置的QPS上限去除以机器数量，然后每台机器得到的就是这样一个平均过后的机器数量。<br>最后以每个node得到的QPS作为令牌痛算法的参数。<br>见下图：</p><p><img src="/images/2021-12-12-12-09-50.png" alt="图二十、QPS上限"></p><h4 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h4><p>我们用直观的离线串行（旧的线上版本）任务和我们的拓扑离线任务在性能上做了一个简单A/B Test：</p><p>同等计算资源前提下，数据集成过程性能提升100%。230w左右的离线任务量用原本串行执行的方式大概需要一小时三四十分钟。现在使用以disruptor为主的这套方案只需要不到三四十分钟左右。大大减轻了那些强依赖我们任务结果的下游的处理时间负担（比如我们的大多数任务需要在凌晨几点前跑完用于算法分析）</p><h3 id="畅想"><a href="#畅想" class="headerlink" title="畅想"></a>畅想</h3><p>其实我们面对的场景是一个相对通用的场景，因此也是我们想要展示给大家看的地方。除了策略中心，我想计划域补货计算等许多产品都在面对我们相似的场景。因此希望提供出来给大家借鉴和指教。</p><h3 id="感谢"><a href="#感谢" class="headerlink" title="感谢"></a>感谢</h3><p>特别感谢我的师兄灵帝在实现这个的整个过程中对我的支持和讨论，包括后期上线的灰度方案和数据对账，其实都来自于他的经验和沉淀，如果没有这些，我不知道还要踩多少坑。。。</p><p>其次感谢今年来实习的眉伯同学，一开始的思路验证工作做的很好。</p><p>最后也感谢我们团队的CodeReview机制，让我发现了自己许多代码的问题。</p><p>Respect！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据集成场景优化——任务编排-限流&quot;&gt;&lt;a href=&quot;#数据集成场景优化——任务编排-限流&quot; class=&quot;headerlink&quot; title=&quot;数据集成场景优化——任务编排/限流&quot;&gt;&lt;/a&gt;数据集成场景优化——任务编排/限流&lt;/h1&gt;&lt;h2 id=&quot;资料&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式计算" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>关于Broker的二三事</title>
    <link href="https://kairbon.github.io/2021/11/11/Broker/"/>
    <id>https://kairbon.github.io/2021/11/11/Broker/</id>
    <published>2021-11-11T10:52:41.000Z</published>
    <updated>2022-02-10T15:08:35.121Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于Broker的二三事"><a href="#关于Broker的二三事" class="headerlink" title="关于Broker的二三事"></a>关于Broker的二三事</h1><h2 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h2><p>说起Broker其实第一次见到是在公司的一个中间件上，这个中间件使用broker的语义去创建一个服务，当时就有些疑惑。今天又在一篇技术文章中发现了这个关键字眼，遂研究之。</p><h2 id="过程："><a href="#过程：" class="headerlink" title="过程："></a>过程：</h2><p>Broker在维基百科的定义如下：A broker is a person or firm who arranges transactions between a <a href="https://en.wikipedia.org/wiki/Purchasing">buyer</a> and a <a href="https://en.wikipedia.org/wiki/Sales">seller</a> for a <a href="https://en.wikipedia.org/wiki/Commission_(remuneration)">commission</a> when the deal is executed. A broker who also acts as a seller or as a buyer becomes a <a href="https://en.wiktionary.org/wiki/principal">principal</a> party to the deal. Neither role should be confused with that of an <a href="https://en.wikipedia.org/wiki/Agent_(law)">agent</a>—one who acts on behalf of a principal party in a deal.</p><p>一句话解释就是类似中间人/中介的角色，供给方和需求方的中介。在kafka的架构中，broker是真正持有Topic的核心中的核心，因此在kafka的传统架构中，通常使用zookeeper去保证这部分的高可用性。</p><p><img src="/images/kafka%E6%9E%B6%E6%9E%84.png" alt="image-20211111101803924"></p><p><img src="/images/kafka%E4%BD%BF%E7%94%A8zookeeper.png" alt="image-20211111101909749"></p><p>可以看到，在kafka的场景中，broker不仅是一个抽象的概念（可以通过代码去操作它，描述它），也是一个相对独立的实例。（部署结构上，broker也可以独立部署去服务）</p><p>而在其他的场景下我也发现了broker，比如传统的很多服务发现和注册中心（或者叫做软路由）其实就是一个broker，比如阿里常用的HSF的服务注册和发现模块。也是有着许多高可用的保证方案支持。</p><p><img src="/images/hsf-broker.png" alt="image-20211111143631601"></p><p>从整体的结构上都是极其重要的一环。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>进过一番探索，感觉其实broker就是一个基础的词语，它在不同的场景有着不同的实现。但本质其实就是个中介。</p><ol><li>首先你可以收拢和管理所有的生产方和消费方的连接。基于这个连接做一些事情。比如路由和篡改消息。</li><li>其次Broker对生产方和消费方提供完全不同的服务。 1.降低生产方和消费方的对接成本。2.保障生产方和服务方的中间资料。</li></ol><p>但可能也会造成一些问题。比如：</p><ol><li>中心化导致的性能热点和可用性问题。因此需要为其配备高可用方案。</li><li>一些简单的服务和需求使用broker反而会造成浪费。比如A和B想要达成某种特殊协议，走点对点的方式即可，成本和稳定性和可控程度高。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;关于Broker的二三事&quot;&gt;&lt;a href=&quot;#关于Broker的二三事&quot; class=&quot;headerlink&quot; title=&quot;关于Broker的二三事&quot;&gt;&lt;/a&gt;关于Broker的二三事&lt;/h1&gt;&lt;h2 id=&quot;背景：&quot;&gt;&lt;a href=&quot;#背景：&quot; class</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>未来Faas的思考</title>
    <link href="https://kairbon.github.io/2021/10/14/%E6%9C%AA%E6%9D%A5Faas%E7%9A%84%E6%80%9D%E8%80%83/"/>
    <id>https://kairbon.github.io/2021/10/14/%E6%9C%AA%E6%9D%A5Faas%E7%9A%84%E6%80%9D%E8%80%83/</id>
    <published>2021-10-14T09:46:01.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="现状简介"><a href="#现状简介" class="headerlink" title="现状简介"></a>现状简介</h2><p><img src="/images/%E7%8E%B0%E4%BB%A3Faas.png" alt="现代Faas"></p><p>以阿里云的FC举例，业务在使用JAVA语言时，时常遇到一个问题，就是每个函数都需要一个独立的容器（docker）启动，有时候我们会将函数的粒度拆分的比较小。比如一个报表业务系统中，有三四十个QPS不到1的函数，这种情况会对FC的资源利用率造成比较大的挑战。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol><li>Java Runtime 资源利用率高，同一个项目，每个函数都占用一个docker，浪费大。</li><li>在优化资源利用率和性能的前提下如何保证安全性：一个函数的异常不影响其他函数的运行。</li></ol><h2 id="Java-Runtime"><a href="#Java-Runtime" class="headerlink" title="Java Runtime"></a>Java Runtime</h2><p>目前基于二方包+冷启动的方式。启动慢，资源利用率低（一个函数对应一个jar包，一个jar包对应一个continer（docker））。需要升级。</p><p>升级需求（已有中间件能够支持的不考虑）：</p><ol><li>调度粒度更细（单continer内部多JAVA  Func）</li><li>支持调度-将调度的过程拆分。 A进程将bundleA 终止，卸载。 B进程将bundleA拉取，启动。通过中心化的调度管理中心统一调度。</li><li>监控</li><li>JVM内部管理</li></ol><h3 id="方式一：JAVA单进程运行时加载-完善的函数生命周期。"><a href="#方式一：JAVA单进程运行时加载-完善的函数生命周期。" class="headerlink" title="方式一：JAVA单进程运行时加载+完善的函数生命周期。"></a>方式一：JAVA单进程运行时加载+完善的函数生命周期。</h3><p>核心：指定classloader。</p><h4 id="OSGI思想"><a href="#OSGI思想" class="headerlink" title="OSGI思想"></a>OSGI思想</h4><h5 id="Karaf：https-karaf-apache-org-manual-latest-prerequisites"><a href="#Karaf：https-karaf-apache-org-manual-latest-prerequisites" class="headerlink" title="Karaf：https://karaf.apache.org/manual/latest/#_prerequisites"></a>Karaf：<a href="https://karaf.apache.org/manual/latest/#_prerequisites">https://karaf.apache.org/manual/latest/#_prerequisites</a></h5><p>karaf-docker run 命令记录 使用的是apache的官方docker镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 80:8090 -v /Users/kaiwang/karaf/deploy:/opt/apache-karaf/deplo apache/karaf</span><br></pre></td></tr></table></figure><h5 id="NBF：-https-blog-csdn-net-yunqiinsight-article-details-100976310"><a href="#NBF：-https-blog-csdn-net-yunqiinsight-article-details-100976310" class="headerlink" title="NBF： https://blog.csdn.net/yunqiinsight/article/details/100976310"></a>NBF： <a href="https://blog.csdn.net/yunqiinsight/article/details/100976310">https://blog.csdn.net/yunqiinsight/article/details/100976310</a></h5><h3 id="方式二：JVM多租户（JVM级别优化）"><a href="#方式二：JVM多租户（JVM级别优化）" class="headerlink" title="方式二：JVM多租户（JVM级别优化）"></a>方式二：JVM多租户（JVM级别优化）</h3><h3 id="方式三：多JVM-–-性能"><a href="#方式三：多JVM-–-性能" class="headerlink" title="方式三：多JVM – 性能"></a>方式三：多JVM – 性能</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;现状简介&quot;&gt;&lt;a href=&quot;#现状简介&quot; class=&quot;headerlink&quot; title=&quot;现状简介&quot;&gt;&lt;/a&gt;现状简介&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/%E7%8E%B0%E4%BB%A3Faas.png&quot; alt=&quot;现代Faas&quot;&gt;&lt;/p</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>供应链简易产品设计（PRD）</title>
    <link href="https://kairbon.github.io/2021/09/12/%E4%BE%9B%E5%BA%94%E9%93%BE%E7%AE%80%E6%98%93%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"/>
    <id>https://kairbon.github.io/2021/09/12/%E4%BE%9B%E5%BA%94%E9%93%BE%E7%AE%80%E6%98%93%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/</id>
    <published>2021-09-12T10:18:26.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<p>为了加深和巩固我们对前面供应链分享的理解，所以我们自己实现一个供应链系统。回顾前面的供应链业务及产品介绍，完整的供应链系统非常复杂。即使仅考虑啤酒游戏也会发现涉及多角色，多流程，多单据生命周期等。无需设计这么全面和复杂，考核核心单据即可。比如计划域一个计划单就好。本次我们只cover补货链路。并且支持多租户</p><p><em>计划单：planOrder， 采购单：purchaseOrder，入库单：inStoreOrder</em> </p><h2 id="1、简易流程"><a href="#1、简易流程" class="headerlink" title="1、简易流程"></a>1、简易流程</h2><p><img src="/images/image-process.png" alt="流程图和状态图"></p><h3 id="1-1-计划单"><a href="#1-1-计划单" class="headerlink" title="1.1 计划单"></a>1.1 计划单</h3><p>维度：品仓</p><p>操作：增删查改</p><h3 id="1-2-采购单"><a href="#1-2-采购单" class="headerlink" title="1.2 采购单"></a>1.2 采购单</h3><p>维度：品仓</p><p>操作：增删查改</p><h3 id="1-3-出入库单"><a href="#1-3-出入库单" class="headerlink" title="1.3 出入库单"></a>1.3 出入库单</h3><p>维度：品仓</p><p>操作：查看和修改已到仓状态</p><h2 id="2、线上系统（一个表单系统该有的样子，待UX-UE）"><a href="#2、线上系统（一个表单系统该有的样子，待UX-UE）" class="headerlink" title="2、线上系统（一个表单系统该有的样子，待UX+UE）"></a>2、线上系统（一个表单系统该有的样子，待UX+UE）</h2><h2 id="3、涉及主数据（注意租户的隔离）"><a href="#3、涉及主数据（注意租户的隔离）" class="headerlink" title="3、涉及主数据（注意租户的隔离）"></a>3、涉及主数据（注意租户的隔离）</h2><h3 id="3-1-品数据"><a href="#3-1-品数据" class="headerlink" title="3.1 品数据"></a>3.1 品数据</h3><p>必须字段：</p><p>货品id，</p><p>货品名称。</p><h3 id="3-2-仓数据"><a href="#3-2-仓数据" class="headerlink" title="3.2 仓数据"></a>3.2 仓数据</h3><p>必须字段：</p><p>仓id，</p><p>仓名称。</p><h3 id="3-3-供应商数据"><a href="#3-3-供应商数据" class="headerlink" title="3.3 供应商数据"></a>3.3 供应商数据</h3><p>必须字段：</p><p>商id，</p><p>商名称。</p><h2 id="4-单据表（注意租户的隔离）"><a href="#4-单据表（注意租户的隔离）" class="headerlink" title="4. 单据表（注意租户的隔离）"></a>4. 单据表（注意租户的隔离）</h2><h3 id="4-1-计划单"><a href="#4-1-计划单" class="headerlink" title="4.1 计划单"></a>4.1 计划单</h3><p>单据id，品信息，目的仓信息，数量，供应商信息，状态， 创建时间， 下发时间， 租户， 计划到达时间。</p><p>状态：0-待下发，1-待审核，2-已审核下发，-1-已关闭。</p><h3 id="4-2-采购单"><a href="#4-2-采购单" class="headerlink" title="4.2 采购单"></a>4.2 采购单</h3><p>单据id，品信息， 目的仓信息，数量，总价格，状态， 创建时间， 下发时间，关联计划单单号，租户， 计划到达时间。</p><p>状态：0-待下发，1-待审核，2-已审核下发， 3已完成，-1-已关闭。</p><h3 id="4-3-出入库单"><a href="#4-3-出入库单" class="headerlink" title="4.3 出入库单"></a>4.3 出入库单</h3><p>单据id，品信息， 目的仓信息，数量，入库时间，状态，创建时间，关联采购单单号，租户， 计划到达时间。</p><p>状态：0-运输中，1-以到仓。</p><h2 id="5、功能"><a href="#5、功能" class="headerlink" title="5、功能"></a>5、功能</h2><h3 id="5-1-补货计划"><a href="#5-1-补货计划" class="headerlink" title="5.1 补货计划"></a>5.1 补货计划</h3><ul><li><p>产品功能（简化业务逻辑为手工补货，不考虑建议和采纳问题）</p><ul><li>新增补货计划</li><li>查询补货计划</li><li>修改补货计划</li></ul></li><li><p>补货计划要素</p><ul><li>品</li><li>仓</li><li>时间（创建时间和下发时间）</li><li>供应商</li><li>数量</li></ul></li></ul><h3 id="5-2-采购计划"><a href="#5-2-采购计划" class="headerlink" title="5.2 采购计划"></a>5.2 采购计划</h3><ul><li>产品功能（简化业务逻辑为手工补货，不考虑建议和采纳问题）<ul><li>新增采购计划</li><li>查询采购计划</li><li>修改采购计划</li></ul></li><li>采购计划要素<ul><li>品</li><li>仓</li><li>时间（创建时间和下发时间）</li><li>供应商</li><li>数量</li><li>价格</li><li>关联计划单单号</li></ul></li></ul><h3 id="5-3-出入库单"><a href="#5-3-出入库单" class="headerlink" title="5.3 出入库单"></a>5.3 出入库单</h3><ul><li>按照计划时间，供应商送货，送满率 100%（即计划量会被100%满足）；</li><li>送货到入库时间约定为1周，即1周会进行入库；</li><li>关联采购单单号。</li></ul><h2 id="6、mock数据"><a href="#6、mock数据" class="headerlink" title="6、mock数据"></a>6、mock数据</h2><p>品</p><table><thead><tr><th>id</th><th>品名称</th><th>租户</th></tr></thead><tbody><tr><td>1</td><td>测试品1</td><td>1</td></tr><tr><td>2</td><td>测试品2</td><td>1</td></tr><tr><td>3</td><td>测试品3</td><td>1</td></tr><tr><td>4</td><td>测试品4</td><td>6</td></tr><tr><td>5</td><td>测试品5</td><td>6</td></tr><tr><td>6</td><td>测试品6</td><td>6</td></tr></tbody></table><p>仓</p><table><thead><tr><th>id</th><th>仓名称</th><th>租户</th></tr></thead><tbody><tr><td>1</td><td>测试仓1</td><td>1</td></tr><tr><td>2</td><td>测试仓2</td><td>1</td></tr><tr><td>3</td><td>测试仓3</td><td>1</td></tr><tr><td>4</td><td>测试仓4</td><td>6</td></tr><tr><td>5</td><td>测试仓5</td><td>6</td></tr><tr><td>6</td><td>测试仓6</td><td>6</td></tr></tbody></table><p>商</p><table><thead><tr><th>id</th><th>商名称</th><th>租户</th></tr></thead><tbody><tr><td>1</td><td>测试商1</td><td>1</td></tr><tr><td>2</td><td>测试商2</td><td>1</td></tr><tr><td>3</td><td>测试商3</td><td>1</td></tr><tr><td>4</td><td>测试商4</td><td>6</td></tr><tr><td>5</td><td>测试商5</td><td>6</td></tr><tr><td>6</td><td>测试商6</td><td>6</td></tr></tbody></table><h2 id="7、页面操作"><a href="#7、页面操作" class="headerlink" title="7、页面操作"></a>7、页面操作</h2><p>计划单：</p><ol><li>查询（计划单号， 状态， 租户）</li><li>表格右上角操作（新建）</li><li>行内操作（修改计划量，关闭计划单，下发计划单）</li><li>新建字段（品id，仓id，数量，供应商id，租户， 计划到达时间）</li></ol><p>采购单：</p><ol><li>查询（采购单号， 状态， 租户）</li><li>表格右上角操作（新建）</li><li>行内操作（关闭采购单, 编辑（可修改，价格，数量））</li><li>新建字段（品id，仓id，数量，供应商id，租户， 计划到达时间）</li></ol><p>入库单：</p><ol><li>查询（入库单号， 状态， 租户）</li><li>行内操作（状态修改-已入库）</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;为了加深和巩固我们对前面供应链分享的理解，所以我们自己实现一个供应链系统。回顾前面的供应链业务及产品介绍，完整的供应链系统非常复杂。即使仅考虑啤酒游戏也会发现涉及多角色，多流程，多单据生命周期等。无需设计这么全面和复杂，考核核心单据即可。比如计划域一个计划单就好。本次我们只</summary>
      
    
    
    
    <category term="产品设计" scheme="https://kairbon.github.io/categories/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="软件工程" scheme="https://kairbon.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="项目经理" scheme="https://kairbon.github.io/tags/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E7%90%86/"/>
    
    <category term="产品经理" scheme="https://kairbon.github.io/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Hbase学习1——从论文讲起（还没搞完）</title>
    <link href="https://kairbon.github.io/2021/08/15/Hbase%E5%AD%A6%E4%B9%A0/"/>
    <id>https://kairbon.github.io/2021/08/15/Hbase%E5%AD%A6%E4%B9%A0/</id>
    <published>2021-08-15T19:35:58.000Z</published>
    <updated>2022-02-10T15:08:35.121Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-从论文讲起"><a href="#1-从论文讲起" class="headerlink" title="1. 从论文讲起"></a>1. 从论文讲起</h2><p>Hbase是一款根据google bigtable论文实现的高性能分布式数据库。Google 的 Bigtable 的设计目的是可靠的处理 PB 级别的数据，并且能够部署到上千台机器上。Bigtable 已经实现了下面的几个目标:适用性广泛、可扩展、高性能和高可用性。</p><p>Bigtable 已经在超过 60 个 Google 的产品和项目上得到了应用，包括 Google Analytics、Google Finance、 Orkut、Personalized Search、Writely 和 Google Earth。这些产品对 Bigtable 提出了迥异的需求，有的需要高吞吐量的批处理，有的则需要及时响应，快速返回数据给最终用户。它们使用的 Bigtable <strong>集群的配置也有很大的差异</strong>，有的集群只有几台Server，而有的则需要上千台Server、存储几百 TB 的数据。</p><h3 id="1-1-数据模型"><a href="#1-1-数据模型" class="headerlink" title="1.1 数据模型"></a>1.1 数据模型</h3><p>Bigtable 不支持完整的关系数据模型；与之相反，Bigtable 为客户提供了简单的数据模型，利用这个模型，客户可以动态控制数据的分布和格式，用户也可以自己推测底层存储数据的位置相关性（我的理解是你如果存储的是二叉树索引，根据字典序排序，因此相同前缀的key会聚集在一起，查询的时候利用这个特性可以更加灵活的调整以提高效率）。数据的下标是行和列的名字，名字可以是任意的字符串。</p><p>Bigtable 是一个稀疏的、分布式的、持久化存储的多维度排序 Map，因此本质上Hbase它其实是一个Map，Map的索引是行关键字、列关键字以及时间戳；Map 中的每个value都是一个未经解析的byte数组。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(row:string, column:string,time:int64)-&gt;string</span><br></pre></td></tr></table></figure><p>Bigtable表中的行关键字可以是任意的字符串(目前支持最大 64KB 的字符串，但是对大多数用户，10-100 个字节就足够了)。**对同一个行关键字的读或者写操作都是原子的(不管读或者写这一行里多少个不同列)**，这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。Bigtable 通过行关键字的字典顺序来组织数据。表中的每个行都可以动态分区。每个分区叫做一个”Tablet”， Tablet 是数据分布和负载均衡调整的最小单位。</p><p><img src="/images/image-20210815134027991.png" alt="image-20210815134027991"></p><p>这里的com.cnn.www是网址，也就是这行的索引，contents是基于时间戳t3，t5，t6存的网站内容，后面的anchor是应用这个网站的源网站。这个例子主要说明bigtable适合使用的场景。</p><h4 id="1-1-1-列族"><a href="#1-1-1-列族" class="headerlink" title="1.1.1 列族"></a>1.1.1 列族</h4><p>列关键字组成的集合叫做“列族“，列族是访问控制的基本单位。存放在同一列族下的所有数据通常都 属于同一个类型(我们可以把同一个列族下的数据压缩在一起)。列族在使用之前必须先创建，然后才能在列 族中任何的列关键字下存放数据;列族创建后，其中的任何一个列关键字下都可以存放数据。根据我们的设 计意图，一张表中的列族不能太多(最多几百个)，并且列族在运行期间很少改变。与之相对应的，一张表可 以有无限多个列。</p><p>列关键字的命名语法如下:列族:限定词。 列族的名字必须是可打印的字符串，而限定词的名字可以是任意的字符串。比如，Webtable 有个列族 language，language 列族用来存放撰写网页的语言。我们在 language列族中只使用一个列关键字，用来存放每个网页的语言标识 ID。Webtable 中另一个有用的列族是 anchor;这 个列族的每一个列关键字代表一个锚链接，如图一所示。Anchor 列族的限定词是引用该网页的站点名;Anchor 列族每列的数据项存放的是链接文本。</p><p>访问控制、磁盘和内存的使用统计都是在列族层面进行的。在我们的 Webtable 的例子中，上述的控制权 限能帮助我们管理不同类型的应用:我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据并创建继承的列族、一些应用则只允许浏览数据(甚至可能因为隐私的原因不能浏览所有数据)。</p><h4 id="1-1-2-时间戳"><a href="#1-1-2-时间戳" class="headerlink" title="1.1.2 时间戳"></a>1.1.2 时间戳</h4><p>在 Bigtable 中，表的每一个数据项都可以包含同一份数据的不同版本;不同版本的数据通过时间戳来索引。Bigtable 时间戳的类型是 64 位整型。Bigtable 可以给时间戳赋值，用来表示精确到毫秒的“实时”时间; 用户程序也可以给时间戳赋值。如果应用程序需要避免数据版本冲突，那么它必须自己生成具有唯一性的时间戳。数据项中，不同版本的数据按照时间戳倒序排序，即最新的数据排在最前面。</p><p>为了减轻多个版本数据的管理负担，我们对每一个列族配有两个设置参数，Bigtable 通过这两个参数可以 对废弃版本的数据自动进行垃圾收集。用户可以指定只保存最后 n 个版本的数据，或者只保存“足够新”的 版本的数据(比如，只保存最近7天的内容写入的数据。</p><p>在 Webtable 的举例里，contents:列存储的时间戳信息是网络爬虫抓取一个页面的时间。内置的垃圾收集机制可以让我们只保留最近三个版本的网页数据。（用户可以自己配置）</p><h3 id="1-2-架构"><a href="#1-2-架构" class="headerlink" title="1.2 架构"></a>1.2 架构</h3><p>BigTable主要有几个部件：分布式锁，master server，tablet server，tablet</p><p>Bigtable 包括了三个主要的组件:链接到客户程序中的库、一个 Master Server和多个 Tablet Server。针对系统工作负载的变化情况，BigTable可以动态的向集群中添加(或者删除)Tablet Server。</p><p>Master Server主要负责以下工作:为 Tablet Server分配 Tablet、检测新加入的或者过期失效的 Table Server、对Tablet Server进行负载均衡、以及对保存在 GFS 上的文件进行垃圾收集。除此之外，它还处理对模式（scheme）的相关修改操作，例如建立表和列族。</p><p>每个Tablet Server都管理一个Tablet的集合(通常每个Server有大约数十个至上千个 Tablet)。每个Tablet Server负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。</p><p>和很多 Single-Master 类型的分布式存储系统类似，客户端读取的数据都不经过 Master Server: 客户程序直接和 Tablet Server通信进行读写操作。由于 BigTable 的客户程序不必通过 Master Server来获取 Tablet 的位置信息，因此，大多数客户程序甚至完全不需要和 Master Server通信。在实际应用中，Master 服务器的负载是很轻的。</p><p>一个BigTable集群存储了很多表，每个表包含了一个Tablet的集合，而每个Tablet包含了某个范围内的行的所有相关数据。初始状态下，一个表只有一个Tablet。随着表中数据的增长，它被自动分割成多个Tablet， 缺省情况下，每个 Tablet 的尺寸大约是 100MB 到 200MB。</p><p>Bigtable是建立在其它的几个Google基础构件上的。BigTable使用Google的分布式文件系统（GFS）存储日志文件和数据文件。BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable 的进程经常要和其它应用的进程共享机器。BigTable 依赖集群管理系统来调度任务、管理共享的机器上的资源、处理机器的故障、以及监视机器的状态。</p><p>BigTable 内部存储数据的文件是 Google SSTable 格式的。SSTable 是一个持久化的、排序的、不可更改的Map 结构，而 Map 是一个 key-value 映射的数据结构，key 和 value 的值都是任意的 Byte 串。可以对 SSTable 进行如下的操作:查询与一个 key 值相关的 value，或者遍历某个 key 值范围内的所有的 key-value 对。从内部看，SSTable 是一系列的数据块(通常每个块的大小是 64KB，这个大小是可以配置的)。SSTable 使用块索引(通常存储在 SSTable 的最后)来定位数据块;在打开 SSTable 的时候，索引被加载到内存。每次查找都可以通过一次磁盘搜索完成:首先使用二分查找法在内存中的索引里找到数据块的位置，然后再从硬盘读取相 应的数据块。也可以选择把整个 SSTable 都放在内存中，这样就不必访问硬盘了。</p><p><img src="/images/image-20210816222857022.png" alt="image-20210816222857022"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-从论文讲起&quot;&gt;&lt;a href=&quot;#1-从论文讲起&quot; class=&quot;headerlink&quot; title=&quot;1. 从论文讲起&quot;&gt;&lt;/a&gt;1. 从论文讲起&lt;/h2&gt;&lt;p&gt;Hbase是一款根据google bigtable论文实现的高性能分布式数据库。Google 的</summary>
      
    
    
    
    <category term="分布式数据库" scheme="https://kairbon.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="软件工程" scheme="https://kairbon.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>思考自己能做到的（2）梦的张力</title>
    <link href="https://kairbon.github.io/2021/08/14/%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E8%83%BD%E5%81%9A%E5%88%B0%E7%9A%842/"/>
    <id>https://kairbon.github.io/2021/08/14/%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E8%83%BD%E5%81%9A%E5%88%B0%E7%9A%842/</id>
    <published>2021-08-14T19:44:00.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="小张"><a href="#小张" class="headerlink" title="小张"></a>小张</h2><p>小张是一名普通的初中生，他最喜欢的事情是做白日梦。当他最近缺钱了，他可能做一个中彩票或者富豪给他转账一个亿的梦；当他喜欢上某个女生了，他可能做一个和那个女孩牵手或者亲嘴的梦；当他想要某些玩具的时候，他可能会做一个第二天一早在枕头下发现自己最想要的玩具的梦。</p><p>在白日梦里，他无所不能，很多奇奇怪怪的脑洞都是从他的头里冒出来的。比如现在就在幻想他召集了一百个穿黑西装的黑社会，把该死的Jack乱拳打死，打成肉酱，做成肉丸，冲到下水道里。而且重要的是他最后挥了挥手让这群人撤下去，留下了一个又潇洒又无畏的背影。</p><p>”哎～“</p><p>小张长叹一口气，翻了个身，放下了手机。这是他新买的8位量子手机，对于一个普通的孩子来说，是一大笔开支，小张攒了很久，甚至为此变卖了自己老爸送给自己第一部手机。</p><p>小张现在不得不去学校了，去面对一群他其实有点讨厌，但也没那么讨厌的同学。今天是开学日，但小张还没有写完暑期作业，或者说一开始他就不想写，他打算继续像之前一样浑水摸鱼。</p><p>背着包，小张慢慢悠悠的走在这条上学路上，一边走，一边幻想着另一个白日梦。是一个成为黑社会大哥的梦，Jack是他的小弟，他叫Jack跪下，Jack就乖乖的跪下。想到这里，小张的不禁笑出了声，但他又觉得这样有点傻，于是又收敛了笑容，躲过了迎面而来的行人。</p><p>不一会，小张躲着他人的目光走进了教室。教室里吵吵闹闹，大家兴高采烈的交谈着暑假中经历的一切。小张看着吵闹的人群，突然觉得自己格格不入，因为其实他一整个暑假都在家里躺尸。也没有有趣的经历，也没有新认识的人。想到这里小张突然觉得有点烦，他想要和朋友出去玩，可是又觉得和他们没什么共同话题，因为他觉得朋友的话题总有些俗气，他有点不是很喜欢。相比起来他更喜欢沉浸在自己的世界里。比如现在他就边抄答案边想自己的新的白日梦情节。</p><p>啪！</p><p>一声书拍脑门的声音，之见一本厚厚的字典拍在了小张的脑门上，小张猛的站起，死死的盯着那个拿着字典的小个男生，那个男生很瘦，不到一米五的身高，小张一米七的个子和70kg的体重在那个男生面前就像是巨熊和豺狼。小张盯着那个男生，说到，Jack你干啥！</p><p>Jack拿着字典笑着说：“给你打个招呼，你看你咋还急了？” 说完便肆无忌惮的笑了起来，旁边的李四依旧是皮笑肉不笑的冷冷的看着小张。</p><p>小张怒火攻心，就要忍不住要动手了。不过说实在的，他害怕起冲突，因为他的受害者心理太严重了，他觉得冲突到最后只会让他自己受伤，通常气消了就开始内疚，如果这个时候对方开始攻击他，那么他在这个状态下反而会更加难受，到最后总是会归结于自己是个傻逼，并且时间长了还会产生怨气。所以很多人看小张长得很高大彪悍于是害怕和他接触，但和他相处久的朋友都知道他其实只是个软弱的好人。</p><p>小张又一次的怂了，因为他已经有点习惯了，这种被无理由的欺负。他缓缓的坐下，继续抄着作业。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;小张&quot;&gt;&lt;a href=&quot;#小张&quot; class=&quot;headerlink&quot; title=&quot;小张&quot;&gt;&lt;/a&gt;小张&lt;/h2&gt;&lt;p&gt;小张是一名普通的初中生，他最喜欢的事情是做白日梦。当他最近缺钱了，他可能做一个中彩票或者富豪给他转账一个亿的梦；当他喜欢上某个女生了，他可能</summary>
      
    
    
    
    <category term="随笔系列" scheme="https://kairbon.github.io/categories/%E9%9A%8F%E7%AC%94%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="这就是生活" scheme="https://kairbon.github.io/tags/%E8%BF%99%E5%B0%B1%E6%98%AF%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>2021年每日打卡-坚持了没多久- -</title>
    <link href="https://kairbon.github.io/2021/08/11/%E6%AF%8F%E6%97%A5%E6%89%93%E5%8D%A1/"/>
    <id>https://kairbon.github.io/2021/08/11/%E6%AF%8F%E6%97%A5%E6%89%93%E5%8D%A1/</id>
    <published>2021-08-11T21:58:01.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<p>2021.10.18 今天突然想看会书，遂翻阅之，不过很快感到无趣。因为我不是很感兴趣关于大脑观测维度的理论演进历史的方面，但往好处想，也算是获得了一些有用无用的谈资。</p><p>2021.10.14 感觉自己有点累的时候就不要强行打起精神了。尊重生物本能。（今天看了看自己的所谓自律，还是感觉像在自我安慰）</p><table><thead><tr><th>打卡项</th><th>打卡日期</th><th>完成质量</th></tr></thead><tbody><tr><td>背单词</td><td>2021.10.12</td><td>10分钟 review</td></tr><tr><td>看书</td><td>2021.10.18</td><td>15分钟</td></tr></tbody></table><span id="more"></span><h2 id="2021-9"><a href="#2021-9" class="headerlink" title="2021.9"></a>2021.9</h2><h3 id="写点什么"><a href="#写点什么" class="headerlink" title="写点什么"></a>写点什么</h3><p>2021.9.21 发现了一本我喜欢的书《大脑的一天》。是挺有趣的。</p><h3 id="打卡记录"><a href="#打卡记录" class="headerlink" title="打卡记录"></a>打卡记录</h3><table><thead><tr><th>打卡项</th><th>打卡日期</th><th>完成质量</th></tr></thead><tbody><tr><td>背单词</td><td>2020.9.1-2020.9.19</td><td>30分钟</td></tr><tr><td>背单词</td><td>2020.9.4</td><td>30分钟</td></tr></tbody></table><h2 id="2021-8"><a href="#2021-8" class="headerlink" title="2021.8"></a>2021.8</h2><h3 id="打卡记录-1"><a href="#打卡记录-1" class="headerlink" title="打卡记录"></a>打卡记录</h3><table><thead><tr><th>打卡项</th><th>打卡日期</th><th>完成质量</th></tr></thead><tbody><tr><td>健身</td><td>2020.8.11-2020.8.12</td><td>10分钟Hit</td></tr><tr><td>健身</td><td>2020.8.14</td><td>10分钟Hit</td></tr><tr><td>学习</td><td>2020.8.15</td><td>120分钟论文阅读</td></tr><tr><td>背单词</td><td>2020.8.17-2020.8.21</td><td>30分钟</td></tr><tr><td>波比跳+仰卧起坐</td><td>2020.8.21</td><td>30分钟</td></tr><tr><td>背单词</td><td>2020.8.23-2020.8.27</td><td>30分钟</td></tr><tr><td>背单词</td><td>2020.8.30-2020.8.31</td><td>30分钟</td></tr><tr><td>波比跳+仰卧起坐</td><td>2020.8.28/29？记不太清了</td><td>30分钟</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">&lt;p&gt;2021.10.18 今天突然想看会书，遂翻阅之，不过很快感到无趣。因为我不是很感兴趣关于大脑观测维度的理论演进历史的方面，但往好处想，也算是获得了一些有用无用的谈资。&lt;/p&gt;
&lt;p&gt;2021.10.14 感觉自己有点累的时候就不要强行打起精神了。尊重生物本能。（今天看了看自己的所谓自律，还是感觉像在自我安慰）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;打卡项&lt;/th&gt;
&lt;th&gt;打卡日期&lt;/th&gt;
&lt;th&gt;完成质量&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;背单词&lt;/td&gt;
&lt;td&gt;2021.10.12&lt;/td&gt;
&lt;td&gt;10分钟 review&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;看书&lt;/td&gt;
&lt;td&gt;2021.10.18&lt;/td&gt;
&lt;td&gt;15分钟&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</summary>
    
    
    
    <category term="打卡" scheme="https://kairbon.github.io/categories/%E6%89%93%E5%8D%A1/"/>
    
    
    <category term="这就是生活" scheme="https://kairbon.github.io/tags/%E8%BF%99%E5%B0%B1%E6%98%AF%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>思考自己能做到的（1）开篇</title>
    <link href="https://kairbon.github.io/2021/08/08/%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E8%83%BD%E5%81%9A%E5%88%B0%E7%9A%841/"/>
    <id>https://kairbon.github.io/2021/08/08/%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E8%83%BD%E5%81%9A%E5%88%B0%E7%9A%841/</id>
    <published>2021-08-08T20:31:00.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-这是什么？"><a href="#1-这是什么？" class="headerlink" title="1. 这是什么？"></a>1. 这是什么？</h2><p>这是我个人的在生活中，工作中遇到的事情和我的一些感想。包括一些回忆性的东西。打算以博客书的方式展开连载。</p><h2 id="2-我为什么要写这个"><a href="#2-我为什么要写这个" class="headerlink" title="2. 我为什么要写这个"></a>2. 我为什么要写这个</h2><p>首先是这本书的题目，是我最近看的动漫《排球少年》中某一集的名字，也是《我们的重制人生》中某一集的名字，我觉得这个题目挺耐人寻味的。这两部动漫也都蛮好看的。</p><p>一方面训练自己的结构化思维和写作技巧，另一方面通过和虚假的自我人格对话，让我从认知层面更理解我自己。</p><p>这样做有几个可预见的对我的好处：1. 让自己表达更加容易让别人理解。2. 未经审视的人生是不值得过的，随着阅历的增长我越发觉得look back的重要性。自我在展现的时候是伴随着情绪的，有时“入戏太深”或者有时候就是没能捕捉到自己的变化，因此我想把这些当时忽略的细碎的事情说出来并且展开思考。3. 纠结某些事情的时候写下来是一个能够让自己静下来的很好的方式。</p><h2 id="3-我要怎么写"><a href="#3-我要怎么写" class="headerlink" title="3. 我要怎么写"></a>3. 我要怎么写</h2><p>在这个系列中每篇我都想要以不同的文体和风格去写，可以理解为每章都是一个命题作文。因为是博客书，所以目录编排还有结构可能会粗糙一些。</p><h2 id="4-感想"><a href="#4-感想" class="headerlink" title="4. 感想"></a>4. 感想</h2><p>我个人目前是一个敏感度蛮高的人（可能不是先天形成的）。这就导致我经常被各种捕捉到的念头给打扰，有时沉浸在过往的感情经历，有时是一些无所吊谓的小细节，有时是一些哲学向的思考。首先我指的打扰是指在我想要，我知道我应该干什么，应该全神贯注于某些事情的时候突然想到其他的事情，目前来看我似乎无法控制这种联想，我尝试过压抑，尝试过宣泄，尝试过很多种心理防御机制但似乎作用不大。但是偶尔有一天，我突发奇想打开了电脑，写下了自己的想法，只写关于自己的事。我感觉到整个世界都静下来了，这种奇妙的感受是我要做这件事的最基本的动力。</p><p>除此之外，个人的个人表现的欲望（想要得到夸赞和认同或者注视的目光）需要被表达，因此在公共博客上去做这件事情可以让我舒服一点，不至于扭曲自我，从而做一些引起自我人格间矛盾的事情。</p><p>综上，可能我后续的文章也会是这种风格的。：）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-这是什么？&quot;&gt;&lt;a href=&quot;#1-这是什么？&quot; class=&quot;headerlink&quot; title=&quot;1. 这是什么？&quot;&gt;&lt;/a&gt;1. 这是什么？&lt;/h2&gt;&lt;p&gt;这是我个人的在生活中，工作中遇到的事情和我的一些感想。包括一些回忆性的东西。打算以博客书的方式展</summary>
      
    
    
    
    <category term="随笔系列" scheme="https://kairbon.github.io/categories/%E9%9A%8F%E7%AC%94%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="这就是生活" scheme="https://kairbon.github.io/tags/%E8%BF%99%E5%B0%B1%E6%98%AF%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（9）-API</title>
    <link href="https://kairbon.github.io/2021/06/01/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-API.md/"/>
    <id>https://kairbon.github.io/2021/06/01/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-API.md/</id>
    <published>2021-06-01T18:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-API"><a href="#基于Raft协议的NoSQL数据库的设计和实现-API" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-API"></a>基于Raft协议的NoSQL数据库的设计和实现-API</h2><h3 id="1-设计展示"><a href="#1-设计展示" class="headerlink" title="1. 设计展示"></a>1. 设计展示</h3><p>DistKV自己设计并实现了自己的好用的命令行语言，Demo如下：</p><h4 id="1-String-concept"><a href="#1-String-concept" class="headerlink" title="1. String concept"></a>1. String concept</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">distkv-cli &gt; put &quot;k1&quot; &quot;v1&quot;</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; str.put &quot;k1&quot; &quot;v1&quot;   # the same as `put`</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; get &quot;k1&quot;</span><br><span class="line">distkv-cli &gt; &quot;v1&quot;</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; str.get &quot;k1&quot;       # the same as `get`</span><br><span class="line">distkv-cli &gt; &quot;v1&quot;</span><br></pre></td></tr></table></figure><h4 id="2-List-concept"><a href="#2-List-concept" class="headerlink" title="2. List concept"></a>2. List concept</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">distkv-cli &gt; list.put &quot;k1&quot; &quot;v1&quot; &quot;v2&quot; &quot;v3&quot;</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; list.get &quot;k1&quot;</span><br><span class="line">distkv-cli &gt; [&quot;v1&quot;, &quot;v2&quot;, &quot;v3&quot;]</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; list.lpush &quot;k1&quot; &quot;v4&quot; &quot;v5&quot; &quot;v6&quot;</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; list.rpush &quot;k1&quot; &quot;v7&quot;</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; list.lpop &quot;k1&quot; 2</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; list.get &quot;k1&quot;</span><br><span class="line">distkv-cli &gt; [&quot;v6&quot;, &quot;v1&quot;, &quot;v2&quot;, &quot;v3&quot;, &quot;v7&quot;]</span><br></pre></td></tr></table></figure><h4 id="3-Set-concept"><a href="#3-Set-concept" class="headerlink" title="3. Set concept"></a>3. Set concept</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">distkv-cli &gt; set.put &quot;k1&quot; &quot;v1&quot; &quot;v2&quot; &quot;v3&quot;</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; set.get &quot;k1&quot;</span><br><span class="line">distkv-cli &gt; &#123;&quot;v1&quot;, &quot;v2&quot;, &quot;v3&quot;&#125;</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; set.exists &quot;k1&quot; &quot;v2&quot;</span><br><span class="line">distkv-cli &gt; true</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; set.exists &quot;k1&quot; &quot;v4&quot;</span><br><span class="line">distkv-cli &gt; false</span><br></pre></td></tr></table></figure><h4 id="4-Dict-concept"><a href="#4-Dict-concept" class="headerlink" title="4. Dict concept"></a>4. Dict concept</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">distkv-cli &gt; dict.put &quot;dict1&quot; &quot;k1&quot; &quot;v1&quot; &quot;k2&quot; &quot;v2&quot;</span><br><span class="line">distkv-cli &gt; ok</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; dict.get &quot;dict1&quot;</span><br><span class="line">distkv-cli &gt; &#123; &quot;k1&quot; : &quot;v1&quot;, &quot;k2&quot; : &quot;v2&quot;&#125;</span><br><span class="line"></span><br><span class="line">distkv-cli &gt; dict.get &quot;dict1&quot; &quot;k1&quot;</span><br><span class="line">distkv-cli &gt; &quot;v1&quot;</span><br></pre></td></tr></table></figure><h4 id="5-Table-concept"><a href="#5-Table-concept" class="headerlink" title="5. Table concept"></a>5. Table concept</h4><ol><li>Define your data structure in a schema file named <code>mytables.sc</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">table TaskTable &#123;</span><br><span class="line">  [p]task_id: string;</span><br><span class="line">  [i]driver_id: string;</span><br><span class="line">  task_name: string;</span><br><span class="line">  return_num: int;</span><br><span class="line">  arguments: [string];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">table DriverTable &#123;</span><br><span class="line"> [p]driver_id: string;</span><br><span class="line"> driver_name: string;</span><br><span class="line"> actor_num: int;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol><li>Start an distkv server and execute this command to create table:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; distkv-cli -p 12344 # connect to distkv server</span><br><span class="line">&gt; create TaskTable, DriverTable from mytables.sc</span><br></pre></td></tr></table></figure><ol><li>Add data to the table:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; TaskTable.add &quot;00001&quot;, &quot;22222&quot;, &quot;my_task&quot;, 3, [&quot;1&quot;, &quot;2&quot;]</span><br><span class="line">&lt; ok</span><br><span class="line">&gt; TaskTable.add &quot;00002&quot;, &quot;99999&quot;, &quot;my_task&quot;, 3, [&quot;1&quot;, &quot;2&quot;]</span><br><span class="line">&lt; ok</span><br><span class="line">&gt; TaskTable.add &quot;00003&quot;, &quot;22222&quot;, &quot;my_task&quot;, 3, [&quot;1&quot;, &quot;2&quot;]</span><br><span class="line">&lt; ok</span><br><span class="line">&gt; DriverTable.add &quot;22222&quot;, &quot;my_driver&quot;, 10</span><br><span class="line">&lt; ok</span><br></pre></td></tr></table></figure><ol><li>Query all tasks by driver id:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; TaskTable.query (*) when driver_id == &quot;22222&quot;</span><br><span class="line">&lt;</span><br><span class="line">&lt; task_id      driver_id     task_name      num_return      arguments</span><br><span class="line">&lt; &quot;00001&quot;      &quot;22222&quot;       &quot;my_task&quot;      3               [&quot;1&quot;, &quot;2&quot;]</span><br><span class="line">&lt; &quot;00003&quot;      &quot;22222&quot;       &quot;my_task&quot;      3               [&quot;1&quot;, &quot;2&quot;]</span><br><span class="line">&lt; 2 records</span><br></pre></td></tr></table></figure><p>除此之外，我们还设计了JAVA端的调用语句</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.distkv.client.example;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.distkv.common.entity.sortedList.SlistEntity;</span><br><span class="line"><span class="keyword">import</span> com.google.protobuf.InvalidProtocolBufferException;</span><br><span class="line"><span class="keyword">import</span> java.util.LinkedList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.distkv.client.DefaultDistkvClient;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistkvUsageExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InvalidProtocolBufferException </span>&#123;</span><br><span class="line">    DefaultDistkvClient distkvClient = <span class="keyword">new</span> DefaultDistkvClient(<span class="string">&quot;distkv://127.0.0.1:8082&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (distkvClient.isConnected()) &#123;</span><br><span class="line">      distkvClient.strs().put(<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;v1&quot;</span>);</span><br><span class="line">      distkvClient.sets().put(<span class="string">&quot;k1&quot;</span>, <span class="keyword">new</span> HashSet&lt;&gt;(Arrays.asList(<span class="string">&quot;v1&quot;</span>, <span class="string">&quot;v2&quot;</span>, <span class="string">&quot;v3&quot;</span>, <span class="string">&quot;v3&quot;</span>)));</span><br><span class="line">      distkvClient.lists().put(<span class="string">&quot;k1&quot;</span>, <span class="keyword">new</span> ArrayList&lt;&gt;(Arrays.asList(<span class="string">&quot;v1&quot;</span>, <span class="string">&quot;v2&quot;</span>, <span class="string">&quot;v3&quot;</span>)));</span><br><span class="line">      distkvClient.ints().put(<span class="string">&quot;k1&quot;</span>, <span class="number">1</span>);</span><br><span class="line">      Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">      map.put(<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;v1&quot;</span>);</span><br><span class="line">      map.put(<span class="string">&quot;k2&quot;</span>, <span class="string">&quot;v2&quot;</span>);</span><br><span class="line">      map.put(<span class="string">&quot;k3&quot;</span>, <span class="string">&quot;v3&quot;</span>);</span><br><span class="line">      map.put(<span class="string">&quot;k4&quot;</span>, <span class="string">&quot;v4&quot;</span>);</span><br><span class="line">      distkvClient.dicts().put(<span class="string">&quot;dict1&quot;</span>, map);</span><br><span class="line">      LinkedList&lt;SlistEntity&gt; slist = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">      slist.add(<span class="keyword">new</span> SlistEntity(<span class="string">&quot;a&quot;</span>, <span class="number">10</span>));</span><br><span class="line">      slist.add(<span class="keyword">new</span> SlistEntity(<span class="string">&quot;b&quot;</span>, <span class="number">8</span>));</span><br><span class="line">      slist.add(<span class="keyword">new</span> SlistEntity(<span class="string">&quot;c&quot;</span>, <span class="number">6</span>));</span><br><span class="line">      slist.add(<span class="keyword">new</span> SlistEntity(<span class="string">&quot;d&quot;</span>, <span class="number">4</span>));</span><br><span class="line">      distkvClient.slists().put(<span class="string">&quot;k1&quot;</span>, slist);</span><br><span class="line">      distkvClient.slists().putMember(<span class="string">&quot;k1&quot;</span>, <span class="keyword">new</span> SlistEntity(<span class="string">&quot;s&quot;</span>,<span class="number">100</span>));</span><br><span class="line"></span><br><span class="line">      String strResult = distkvClient.strs().get(<span class="string">&quot;k1&quot;</span>);</span><br><span class="line">      Set&lt;String&gt; setResult = distkvClient.sets().get(<span class="string">&quot;k1&quot;</span>);</span><br><span class="line">      List&lt;String&gt; listResult = distkvClient.lists().get(<span class="string">&quot;k1&quot;</span>);</span><br><span class="line">      Map&lt;String, String&gt; mapResult = distkvClient.dicts().get(<span class="string">&quot;dict1&quot;</span>);</span><br><span class="line">      LinkedList&lt;SlistEntity&gt; slistResult = distkvClient.slists().top(<span class="string">&quot;k1&quot;</span>, <span class="number">3</span>);</span><br><span class="line">      <span class="keyword">int</span> intResult = distkvClient.ints().get(<span class="string">&quot;k1&quot;</span>);</span><br><span class="line">      distkvClient.ints().incr(<span class="string">&quot;k1&quot;</span>, -<span class="number">2</span>);</span><br><span class="line">      <span class="keyword">int</span> intResultAfterIncr = distkvClient.ints().get(<span class="string">&quot;k1&quot;</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//print String result</span></span><br><span class="line">      System.out.println(<span class="string">&quot;The result of distkvClient.strs().get(\&quot;k1\&quot;) is: &quot;</span> + strResult);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//print set result</span></span><br><span class="line">      System.out.println(<span class="string">&quot;The result of distkvClient.sets().get(\&quot;k1\&quot;) is: &quot;</span> + setResult);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//print list result</span></span><br><span class="line">      System.out.println(<span class="string">&quot;The result of distkvClient.lists().get(\&quot;k1\&quot;) is: &quot;</span> + listResult);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//print dictionary result</span></span><br><span class="line">      System.out.println(<span class="string">&quot;The result of distkvClient.dicts().get(\&quot;dict1\&quot;) is: &quot;</span> + mapResult);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//print sortedList result</span></span><br><span class="line">      System.out.println(<span class="string">&quot;The top3 entities in the \&quot;k1\&quot; of distkvClient.sortedLists() is: &quot;</span> +</span><br><span class="line">          <span class="string">&quot;&#123; First: &quot;</span> + slistResult.get(<span class="number">0</span>).getMember() +</span><br><span class="line">          <span class="string">&quot;; Second: &quot;</span> + slistResult.get(<span class="number">1</span>).getMember() +</span><br><span class="line">          <span class="string">&quot;; Third: &quot;</span> + slistResult.get(<span class="number">2</span>).getMember() + <span class="string">&quot;; &#125;&quot;</span>);</span><br><span class="line">      System.out.println(<span class="string">&quot;In the key \&quot;k1\&quot; of distkvClient.sortedLists(), the member name is &quot;</span></span><br><span class="line">          + <span class="string">&quot;\&quot;a\&quot;, its rank is &quot;</span> + distkvClient.slists().getMember(<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;a&quot;</span>).getSecond()</span><br><span class="line">          + <span class="string">&quot; and its score is &quot;</span> + distkvClient.slists().getMember(<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;a&quot;</span>).getFirst());</span><br><span class="line"></span><br><span class="line">      <span class="comment">// print ints result</span></span><br><span class="line">      System.out.println(<span class="string">&quot;The result of distkvClient.ints().get(\&quot;k1\&quot;) is: &quot;</span> + intResult);</span><br><span class="line">      System.out.println(<span class="string">&quot;The result of distkvClient.ints().get(\&quot;k1\&quot;) &quot;</span></span><br><span class="line">          + <span class="string">&quot;after increasing the value -2 is: &quot;</span> + intResultAfterIncr);</span><br><span class="line"></span><br><span class="line">      distkvClient.disconnect();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-2-错误码设计"><a href="#1-2-错误码设计" class="headerlink" title="1.2 错误码设计"></a>1.2 错误码设计</h3><p>Dst的错误码以特定的规则提供了用以明确用户命令语句在执行过程中发生的任何错误的信息。根据ErrorCode的规则，用户可以清楚的从中解读出错误的类信息。</p><h4 id="1-2-1-ErrorCode设计思路："><a href="#1-2-1-ErrorCode设计思路：" class="headerlink" title="1.2.1 ErrorCode设计思路："></a>1.2.1 ErrorCode设计思路：</h4><p>1.错误码尽可能具有正则性。</p><p>  我们希望dst的错误码应尽可能具有正则性，即不同错误码，同位的相同的码字应代表同性质的错误信息。</p><p>2.错误码的每一位都代表一级错误信息。</p><p>  这意味着各种错误码在同一位上的不同码字代表着不同的错误类但这些错误类是同级别的。</p><p>3.错误码的低位代表的错误类是高位代表的错误类的概念上的子类。换言之，低位提供的错误信息是高位提供的错误信息的更具体错误。</p><p>关于“尽可能正则”的解释：</p><p>DistKV的错误信息有着一定的特殊性——每个数据类型下往往含有其独有的错误类，比如说Dict类下DictKeyNotFound错误类就是其所独有的。还有就是语法错误与解析错误应该是同级错误，但二者内含的子错误完全不同。这种特点使得Dst ErrorCode难以实现完全的正则化。</p><h4 id="1-2-2-ErrorCode设计规则："><a href="#1-2-2-ErrorCode设计规则：" class="headerlink" title="1.2.2 ErrorCode设计规则："></a>1.2.2 ErrorCode设计规则：</h4><p>Dst ErrorCode共4位，第一位为字母，后三位为数字。</p><p>第一位：错误发生的数据类/语法错误</p><p>对应关系：</p><p>Dict       ——       D</p><p>List       ——       L</p><p>Set        ——      S</p><p>String      ——      C</p><p>(SortedList   ——      O)</p><p>（Table      ——      T）</p><p>语法错误    ——      X</p><p>第二位：通用高级错误类（待补充）</p><p>对应关系：</p><p>KeyNotFound     ——     1</p><p>OutOfBounds     ——     2</p><p>参数数量错误     ——     3</p><p>第三位：语法错误标识</p><p>对应关系：</p><p>无法理解的输入     ——     1</p><p>第四位：具体错误类（如果表错误包含在内的话，可能需要由第一位决定语义）</p><p>对应关系：</p><p>DictKeyNotFound          ——     1</p><p>ListIndexOutOfBounds      ——     2</p><p>SetNonExistentItem        ——     3</p><p>SortedListNonFoundItem    ——     4)</p><p>SortedListTopNumBePositive  ——     5)</p><p>示例：</p><p>D100：</p><p>Dict类下发生的KeyNotFound，后两位为0是由于这不是语法错误，而且在发生KeyNotFound的情况下一般不会发生别的错误。</p><p>L202:</p><p>List类下发生的IndexOutOfBounds错误。</p><p>X010:</p><p>无法理解的输入错误。</p><p>Errorcode清单：</p><p>X010           ——       语法错误，无法理解的输入。请检查命令是否合法。</p><p>D100           ——       Dict类命令，Key未找到。请检查命令中的Key内容是否正确。</p><p>D300           ——       Dict类命令，参数数量错误。请确认命令的参数是否正确。（错误提示里提示所需的参数数量）</p><p>D001           ——       Dict类命令，要查找的dict中的关键字未找到。请检查命令中的查找关键字是否正确。</p><p>…</p><p>L100           ——       List类命令，Key未找到。请检查命令中的Key内容是否正确。 </p><p>L202           ——       List类命令，越界错误，List索引越界。请确认命令中的索引参数是否在List范围内。</p><p>L300           ——       List类命令，参数数量错误。请确认命令的参数是否正确。（错误提示里提示所需的参数数量）</p><p>…</p><p>S100           ——       Set类命令，Key未找到。请检查命令中的Key内容是否正确。</p><p>S300           ——       Set类命令，参数数量错误。请确认命令的参数是否正确。（错误提示里提示所需的参数数量）</p><p>C100           ——       String类命令，Key未找到。请检查命令中的Key内容是否正确。</p><p>C300           ——       String类命令，参数数量错误。请确认命令的参数是否正确。（错误提示里提示所需的参数数量）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-API&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-API&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计和实现-API&quot;&gt;&lt;/a&gt;基于Raf</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（8）-DRPC</title>
    <link href="https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-DRPC/"/>
    <id>https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-DRPC/</id>
    <published>2021-05-21T18:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-DRPC"><a href="#基于Raft协议的NoSQL数据库的设计和实现-DRPC" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-DRPC"></a>基于Raft协议的NoSQL数据库的设计和实现-DRPC</h2><p>在分布式领域，必不可少的就是关于远程通信，我们通常把这部分组件抽离出来，并且将其称之为RPC。</p><ul><li>RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务。</li><li>本地过程调用：如果需要将本地student对象的age+1，可以实现一个addAge()方法，将student对象传入，对年龄进行更新之后返回即可，本地方法调用的函数体通过函数指针来指定。</li><li>远程过程调用：上述操作的过程中，如果addAge()这个方法在服务端，执行函数的函数体在远程机器上，如何告诉机器需要调用这个方法呢？</li></ul><ol><li>首先客户端需要告诉服务器，需要调用的函数，这里函数和进程ID存在一个映射，客户端远程调用时，需要查一下函数，找到对应的ID，然后执行函数的代码。</li><li>客户端需要把本地参数传给远程函数，本地调用的过程中，直接压栈即可，但是在远程调用过程中不再同一个内存里，无法直接传递函数的参数，因此需要客户端把参数转换成字节流，传给服务端，然后服务端将字节流转换成自身能读取的格式，是一个序列化和反序列化的过程。</li><li>数据准备好了之后，如何进行传输？网络传输层需要把调用的ID和序列化后的参数传给服务端，然后把计算好的结果序列化传给客户端，因此TCP层即可完成上述过程。</li></ol><p>那对一个合格的RPC需要解决以下几个问题：</p><ol><li>通信协议（序列化和反序列化）</li><li>动态映射</li><li>API</li></ol><p>对于DRPC来说，我们不仅要实现基本功能，更要足够负荷大数据的性能。于是实现方面我们参考了业界通用的Netty作为脚手架工具去在此基础上实现我们自己的RPC。</p><h3 id="1-RPC架构设计"><a href="#1-RPC架构设计" class="headerlink" title="1. RPC架构设计"></a>1. RPC架构设计</h3><p>Netty是由JBOSS提供的一个java开源框架，现为 Github上的独立项目。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。也就是说，Netty 是一个基于NIO的客户、服务器端的编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户、服务端应用。Netty相当于简化和流线化了网络应用的编程开发过程，例如：基于TCP和UDP的socket服务开发。DRPC基于Netty构建而成。</p><h4 id="1-1-NIO"><a href="#1-1-NIO" class="headerlink" title="1.1 NIO"></a>1.1 NIO</h4><p>NIO和BIO不同，是同步非阻塞的，服务器实现模式为一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。</p><p>在DRPC中，我们将整个远程调用的过程分为两部分，一部分是多路复用部分，我们称之为IO线程，一部分为worker线程，这部分是为了最大程度利用CPU的多核性能。</p><p><img src="/images/image-figure_drpc_1.png" alt="figure 1"></p><center>图一 DRPC架构</center><p>可这样做真的是最大化利用带宽和性能了吗？因为我们使用的是NIO实现标准模式中的Reactor模型标准去构建我们整个RPC，下面先简单介绍一下Reactor，然后再回答这个问题。</p><h4 id="1-2-Reactor模型"><a href="#1-2-Reactor模型" class="headerlink" title="1.2 Reactor模型"></a>1.2 Reactor模型</h4><p>I/O多路复用可以用作并发事件驱动(event-driven)程序的基础，即整个事件驱动模型是一个状态机，包含了状态(state), 输入事件(input-event), 状态转移(transition), 状态转移即状态到输入事件的一组映射。通过I/O多路复用的技术检测事件的发生，并根据具体的事件(通常为读写)，进行不同的操作，即状态转移。</p><p><code>Reactor</code>模式是一种典型的事件驱动的编程模型，<code>Reactor</code>逆置了程序处理的流程，其基本的思想即为<code>Hollywood Principle— &#39;Don&#39;t call us, we&#39;ll call you&#39;</code>。</p><p>普通的函数处理机制为：调用某函数-&gt; 函数执行， 主程序等待阻塞-&gt; 函数将结果返回给主程序-&gt; 主程序继续执行。</p><p><code>Reactor</code>事件处理机制为：主程序将事件以及对应事件处理的方法在<code>Reactor</code>上进行注册, 如果相应的事件发生，<code>Reactor</code>将会主动调用事件注册的接口，即回调函数. <code>libevent</code>即为封装了<code>epoll</code>并注册相应的事件(I/O读写，时间事件，信号事件)以及回调函数，实现的事件驱动的框架。</p><p>使用Reactor模型在工业场景下中有非常明显的优势。</p><p>从结构上区分，可以将Reactor模型分为三种模型：</p><h5 id="1-2-1-单IO线程，单Worker线程。"><a href="#1-2-1-单IO线程，单Worker线程。" class="headerlink" title="1.2.1 单IO线程，单Worker线程。"></a>1.2.1 单IO线程，单Worker线程。</h5><p><img src="/images/image-figure_drpc_2.png" alt="figure 2"></p><center>图二 模型一</center><p>从计算机的角度上讲，在这个流程中，Port是计算机的资源，IO和Woker都是操作系统提供的。从概念上讲，worker线程上注册着真正调用的业务流程，诸如对数据库的读写等。因为worker和IO都是单线程，因此对比传统的BIO并无太大优势。</p><h5 id="1-2-2-单IO线程，多Worker线程"><a href="#1-2-2-单IO线程，多Worker线程" class="headerlink" title="1.2.2 单IO线程，多Worker线程"></a>1.2.2 单IO线程，多Worker线程</h5><p><img src="/images/image-figure_drpc_3.png" alt="figure 3"></p><center>图三 模型二</center><p>当一个请求通过端口进入IO线程中后，采用多路复用IO的方式，然后将请求分发到Worker线程池中，然后分配worker去调用相应的注册时间。</p><h4 id="1-2-3-多IO线程，多Worker线程"><a href="#1-2-3-多IO线程，多Worker线程" class="headerlink" title="1.2.3 多IO线程，多Worker线程"></a>1.2.3 多IO线程，多Worker线程</h4><p><img src="/images/image-figure_drpc_4.png" alt="figure 4"></p><center>图四 模型三</center><p>当一个请求进入端口，操作系统使用epoll方式将tcp链接丢入IO线程池，IO读取完毕后再将其丢入Worker线程池。</p><p>对于我们DRPC来说，采用了模型二去实现，因为通常来说，部署DIstKV的机器是大内存，低计算性能。实践发现我们再这种机器上，采用模型二的性能最好。一方面是因为线程多代表上下文切换开销大，如果线程过多会导致计算资源的浪费。另一方面IO线程使用单线程能够最大程度利用多路复用的优点。</p><h4 id="1-3-编码"><a href="#1-3-编码" class="headerlink" title="1.3 编码"></a>1.3 编码</h4><p>DRPC从网络通信在传输层的使用的TCP协议，从应用层面，我们基于Google的Protobuffer构建了自己的协议。</p><h5 id="1-3-1-Protobuffer"><a href="#1-3-1-Protobuffer" class="headerlink" title="1.3.1 Protobuffer"></a>1.3.1 Protobuffer</h5><p>Protobuffer是Google的语言中立、平台中立、可扩展的，用于序列化结构化数据的序列化框架，类似于XML，但是更小、更快、更简单。您只需定义一次数据的结构化方式，然后就可以使用特殊生成的源代码轻松地在各种数据流和各种语言之间写入和读取结构化数据。</p><p>Protobuffer当前支持Java，Python，Objective-C和C ++生成的代码。使用我们新的proto3语言版本，您还可以使用Dart，Go，Ruby和C＃，并提供更多语言。</p><p>Protobuffer可以为DistKV提供高效便捷的序列化和反序列化的工具支持，并且也和Netty的衔接也很好，可以即写即用，下面介绍一下Protobuffer如何去编码一个简单的Message，从而达到高效快速的目的。</p><p>假设您有以下非常简单的消息定义：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">Test1</span> </span>&#123;</span><br><span class="line">  <span class="keyword">optional</span> <span class="built_in">int32</span> a = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在应用程序中，创建Test1消息并将a设置为150。然后将消息序列化为输出流。如果您能够检查编码后的消息，则会看到三个字节：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">08 96 01</span><br></pre></td></tr></table></figure><h5 id="1-3-1-1-Base-128-Varints"><a href="#1-3-1-1-Base-128-Varints" class="headerlink" title="1.3.1.1 Base 128 Varints"></a>1.3.1.1 Base 128 Varints</h5><p>要了解您的简Protobuffer编码，您首先需要了解varint。 Varints是一种使用一个或多个字节序列化整数的方法。较小的数字占用较少的字节数。<br>除了最后一个字节外，varint中的每个字节都设置了最高有效位（msb）–这表明还会有其他字节。每个字节的低7位用于以7位为一组存储数字的二进制补码表示，最低有效组在前。<br>因此，例如，这里是数字1 –它是一个字节，因此未设置msb：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0000 0001</span><br></pre></td></tr></table></figure><p>这是300 ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1010 1100 0000 0010</span><br></pre></td></tr></table></figure><p>您如何确定这是300？首先，从每个字节中删除msb，因为这是在告诉我们是否已到达数字的末尾（如您所见，它设置在第一个字节中，因为varint中有多个字节） ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 1010 1100 0000 0010</span><br><span class="line">→ 010 1100  000 0010</span><br></pre></td></tr></table></figure><p>反转两组7位，因为varint存储数字的有效位最低。然后，将它们连接起来以获得最终值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">000 0010  010 1100</span><br><span class="line">→  000 0010 ++ 010 1100</span><br><span class="line">→  100101100</span><br><span class="line">→  256 + 32 + 8 + 4 = 300</span><br></pre></td></tr></table></figure><p>除了上面举例的int32，Protobuffer还支持以下的类型，但本论文不再展开相关的讨论了。</p><table><thead><tr><th align="left">Type</th><th align="left">Meaning</th><th align="left">Used For</th></tr></thead><tbody><tr><td align="left">0</td><td align="left">Varint</td><td align="left">int32, int64, uint32, uint64, sint32, sint64, bool, enum</td></tr><tr><td align="left">1</td><td align="left">64-bit</td><td align="left">fixed64, sfixed64, double</td></tr><tr><td align="left">2</td><td align="left">Length-delimited</td><td align="left">string, bytes, embedded messages, packed repeated fields</td></tr><tr><td align="left">3</td><td align="left">Start group</td><td align="left">groups (deprecated)</td></tr><tr><td align="left">4</td><td align="left">End group</td><td align="left">groups (deprecated)</td></tr><tr><td align="left">5</td><td align="left">32-bit</td><td align="left">fixed32, sfixed32, float</td></tr></tbody></table><p>下面是我们DRPC所使用的协议：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">syntax=<span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;google/protobuf/any.proto&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;common_pb.proto&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.distkv.rpc.protobuf;</span><br><span class="line">option java_package=<span class="string">&quot;com.distkv.rpc.protobuf.generated&quot;</span>;</span><br><span class="line">option java_outer_classname=<span class="string">&quot;DistkvProtocol&quot;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// TODO(qwang): Use ReadOnlyRequestType and WriteRequestType to</span></span><br><span class="line"><span class="comment">// avoid writing some specific handler in code.</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">RequestType</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// basic operations</span></span><br><span class="line">    None = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    EXIT = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    ACTIVE_NAMESPACE = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    DEACTIVE_NAMESPACE = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">    DROP = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    EXPIRE = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">    EXISTS = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">    TTL = <span class="number">7</span>;</span><br><span class="line"></span><br><span class="line">    SYNC_ISSUE = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// string concept</span></span><br><span class="line">    STR_PUT = <span class="number">101</span>;</span><br><span class="line">    STR_GET = <span class="number">102</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// list concept</span></span><br><span class="line">    LIST_PUT = <span class="number">201</span>;</span><br><span class="line">    LIST_GET = <span class="number">202</span>;</span><br><span class="line">    LIST_LPUT = <span class="number">203</span>;</span><br><span class="line">    LIST_RPUT = <span class="number">204</span>;</span><br><span class="line">    LIST_REMOVE = <span class="number">205</span>;</span><br><span class="line">    LIST_MREMOVE = <span class="number">206</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// set concept</span></span><br><span class="line">    SET_PUT = <span class="number">301</span>;</span><br><span class="line">    SET_GET = <span class="number">302</span>;</span><br><span class="line">    SET_PUT_ITEM = <span class="number">304</span>;</span><br><span class="line">    SET_REMOVE_ITEM = <span class="number">305</span>;</span><br><span class="line">    SET_EXISTS = <span class="number">306</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// dict concept</span></span><br><span class="line">    DICT_PUT = <span class="number">401</span>;</span><br><span class="line">    DICT_GET = <span class="number">402</span>;</span><br><span class="line">    DICT_PUT_ITEM = <span class="number">403</span>;</span><br><span class="line">    DICT_GET_ITEM = <span class="number">404</span>;</span><br><span class="line">    DICT_POP_ITEM = <span class="number">405</span>;</span><br><span class="line">    DICT_REMOVE_ITEM = <span class="number">406</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Slist concept</span></span><br><span class="line">    SLIST_PUT = <span class="number">501</span>;</span><br><span class="line">    SLIST_TOP = <span class="number">502</span>;</span><br><span class="line">    SLIST_INCR_SCORE = <span class="number">503</span>;</span><br><span class="line">    SLIST_PUT_MEMBER = <span class="number">504</span>;</span><br><span class="line">    SLIST_REMOVE_MEMBER = <span class="number">505</span>;</span><br><span class="line">    SLIST_GET_MEMBER = <span class="number">506</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// int concept</span></span><br><span class="line">    INT_PUT = <span class="number">601</span>;</span><br><span class="line">    INT_GET = <span class="number">602</span>;</span><br><span class="line">    INT_INCR = <span class="number">603</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message DistkvRequest &#123;</span><br><span class="line">    string key = <span class="number">1</span>;</span><br><span class="line">    RequestType requestType = <span class="number">2</span>;</span><br><span class="line">    google.protobuf.Any request = <span class="number">3</span>;</span><br><span class="line">    string namespace = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message DistkvResponse &#123;</span><br><span class="line">    Status status = <span class="number">1</span>;</span><br><span class="line">    RequestType requestType = <span class="number">2</span>;</span><br><span class="line">    google.protobuf.Any response = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">service DistkvService &#123;</span><br><span class="line">    <span class="function">rpc <span class="title">call</span><span class="params">(DistkvRequest)</span> <span class="title">returns</span> <span class="params">(DistkvResponse)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面展示的是DistKV最基础的请求Message，更多详情可以查看我们发布在github的项目。</p><p>1.3 API</p><p>对于API来说，我们使用了JAVA的CompletableFuture去封装我们的异步客户端，下面是代码展示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.drpc.Stub;</span><br><span class="line"><span class="keyword">import</span> org.drpc.api.Client;</span><br><span class="line"><span class="keyword">import</span> org.drpc.config.ClientConfig;</span><br><span class="line"><span class="keyword">import</span> org.drpc.netty.DrpcClient;</span><br><span class="line"><span class="keyword">import</span> org.drpc.pb.generated.StringProtocol;</span><br><span class="line"><span class="keyword">import</span> org.drpc.session.DrpcSession;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CompletableFuture;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    ClientConfig clientConfig = ClientConfig.builder()</span><br><span class="line">        .address(<span class="string">&quot;127.0.0.1:8080&quot;</span>)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">    Client client = <span class="keyword">new</span> DrpcClient(clientConfig);</span><br><span class="line">    client.open();</span><br><span class="line"></span><br><span class="line">    Stub&lt;ExampleService&gt; stub = <span class="keyword">new</span> Stub&lt;&gt;(ExampleService.class);</span><br><span class="line">    ExampleService service = stub.getService(client);</span><br><span class="line"></span><br><span class="line">    StringProtocol.PutRequest putRequest = StringProtocol.PutRequest.newBuilder()</span><br><span class="line">        .setKey(<span class="string">&quot;dstPut&quot;</span>)</span><br><span class="line">        .setValue(<span class="string">&quot;PutValue&quot;</span>)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">    StringProtocol.GetRequest getRequest = StringProtocol.GetRequest.newBuilder()</span><br><span class="line">        .setKey(<span class="string">&quot;dstGet&quot;</span>).build();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//sync</span></span><br><span class="line">    StringProtocol.GetResponse getResponse = service.get(getRequest).get();</span><br><span class="line">    System.out.println(getResponse.getStatus());</span><br><span class="line">    System.out.println(getResponse.getValue());</span><br><span class="line">    StringProtocol.PutResponse putResponse = service.put(putRequest).get();</span><br><span class="line">    System.out.println(putResponse.getStatus());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//async</span></span><br><span class="line">    CompletableFuture future1 = service.get(getRequest);</span><br><span class="line">    future1.whenComplete((r, t) -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(getResponse.getStatus());</span><br><span class="line">        System.out.println(getResponse.getValue());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    CompletableFuture future2 = service.put(putRequest);</span><br><span class="line">    future2.whenComplete((r, t) -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(putResponse.getStatus());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//session (keep order)</span></span><br><span class="line">    DrpcSession session = DrpcSession.createSession();</span><br><span class="line">    ExampleService sessionService = stub.getService(client, session);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//async (keep order in server)</span></span><br><span class="line">    CompletableFuture sessionFuture1 = sessionService.get(getRequest);</span><br><span class="line">    sessionFuture1.whenComplete((r, t) -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(getResponse.getValue());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    CompletableFuture sessionFuture2 = sessionService.put(putRequest);</span><br><span class="line">    sessionFuture2.whenComplete((r, t) -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(putResponse.getStatus());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    sessionFuture1.get();</span><br><span class="line">    sessionFuture2.get();</span><br><span class="line"></span><br><span class="line">    client.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>服务端的API如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.drpc.DrpcServer;</span><br><span class="line"><span class="keyword">import</span> org.drpc.config.ServerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    ServerConfig serverConfig = ServerConfig.builder()</span><br><span class="line">        .port(<span class="number">8080</span>)</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">    DrpcServer drpcServer = <span class="keyword">new</span> DrpcServer(serverConfig);</span><br><span class="line">    drpcServer.registerService(ExampleService.class, <span class="keyword">new</span> ExampleServiceImpl());</span><br><span class="line">    drpcServer.run();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-性能优化"><a href="#2-性能优化" class="headerlink" title="2. 性能优化"></a>2. 性能优化</h3><p>除了基本的功能实现外，我们还对RPC可能涉及到的性能和功能性瓶颈做了优化：</p><h4 id="2-1-异步驱动"><a href="#2-1-异步驱动" class="headerlink" title="2.1 异步驱动"></a>2.1 异步驱动</h4><p>在大多数场景中，我们使用的是同步的请求-响应式的RPC，但这会对客户端性能产生影响，客户端必须等服务端计算完成后返回结果后才可以做其他的事情，但是采用异步则不一样，用户可以将请求返回后要做的事情注册进异步客户端中，当服务器计算完成后，才会调用所注册的事件。而这段时间中，就无需当前线程等待IO的完成而可以有时间去做其他事情。比如我们RPC客户端的异步流程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   <span class="comment">//async</span></span><br><span class="line">   CompletableFuture future1 = service.get(getRequest);</span><br><span class="line">   future1.whenComplete((r, t) -&gt; &#123;</span><br><span class="line">     <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</span><br><span class="line">       System.out.println(getResponse.getStatus());</span><br><span class="line">       System.out.println(getResponse.getValue());</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;);</span><br><span class="line"><span class="comment">// other op</span></span><br></pre></td></tr></table></figure><p>首先将我们发送一个请求，获取一个Future</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture future1 = service.get(getRequest);</span><br></pre></td></tr></table></figure><p>接着我们向这个future中注册完成后我们需要执行的操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(getResponse.getStatus());</span><br><span class="line">        System.out.println(getResponse.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个注册不是一个耗时操作，因此代码会很快执行到下面的other op，不会占用当前线程去处理。除此之外，我们在异步Server上面也做了一些优化，这部分详情可以参考我们的开源代码。</p><h4 id="2-2-精简结构"><a href="#2-2-精简结构" class="headerlink" title="2.2 精简结构"></a>2.2 精简结构</h4><p>在寻常RPC中，比如阿里巴巴开源的Dobbo中，有许多我们用不到的功能，比如反压，监控，服务注册等，我们目前需要的只是一个点对点的高性能通信框架，因此对于许多扩展，我们选择了不开启，这也为我们提升了不少的性能。</p><h4 id="2-3-DistKV和DRPC的结合优化"><a href="#2-3-DistKV和DRPC的结合优化" class="headerlink" title="2.3 DistKV和DRPC的结合优化"></a>2.3 DistKV和DRPC的结合优化</h4><p>一开始，我们在使用DRPC时，采用的是单IO线程和多工作线程，但是，DistKV要采用WorkerPool的模型去进行数据操作的必要性有多大，因为从实现角度而言，DistKV所采用的DRPC是基于Netty的。对于Netty来说，他的Worker线程池完全可以复用。比如加一个ThreadLocal的变量，也就是Shard。按照架构设计的话也是没有问题的，而且Netty的Worker线程中也有BlockingQueue，这样对一个Shard的操作也是不会出现冲突的情况，会按照入队的顺序去执行相应的操作。</p><p>设计这种结构的最重要的原因是 <strong>解耦</strong>。复用的方法是一种看似可行的策略，但是这会使得整个DRPC和DistKV会有很大的耦合，不利于DRPC项目的发展。当然这个理由其实不太成立，因为如果对于DistKV来说，RPC只是其中一部分，没有必要为了RPC放弃全部。但是除了RPC部分，我们的分布式架构还包括主从同步，数据迁移，容灾恢复，等部分，这些部分每一个都和shard的结构有着千丝万缕的关系，如果考虑了这一点，就不能更好的考虑另一点，而且每做一步都得考虑这对于远程传输性能的影响，从某种程度上增加了思考的负担。和代码编写的难度。</p><p>除此之外， 解耦的另一大好处就是软件升级的成本小，比如我们RPC要做保序的话，完全就可以不考虑其他的限制，只在RPC层面进行考虑。比如如果出现了比Netty性能好的RPC，而线程模型又和Netty不一样，我们就可以无缝切换。但耦合就不行。</p><p>当然除了这些问题，耦合的话好处确实很多，比如，性能，因为没有因为没有DistKV-WorkerPool，线程只是在Netty内部管控，这样管理效率更高，因为只有一个线程池可以对他做各种优化。而且线程数量也少于非耦合，减少了上下文切换所需要的开销。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-DRPC&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-DRPC&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计和实现-DRPC&quot;&gt;&lt;/a&gt;基于</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（7）-Algorithm和Data struct</title>
    <link href="https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Algorithm%E5%92%8CData%20Struct/"/>
    <id>https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Algorithm%E5%92%8CData%20Struct/</id>
    <published>2021-05-21T17:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-Algorithm和Data-struct"><a href="#基于Raft协议的NoSQL数据库的设计和实现-Algorithm和Data-struct" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-Algorithm和Data struct"></a>基于Raft协议的NoSQL数据库的设计和实现-Algorithm和Data struct</h2><h3 id="1-整体流程简介"><a href="#1-整体流程简介" class="headerlink" title="1. 整体流程简介"></a>1. 整体流程简介</h3><p>那一个KV对是如何写入我们数据库的呢？</p><p>首先，客户端需要从dmeta上先获取全局视图，这是因为我们需要通过一致性hash算法确定我们的key要打入或从哪个partition中获取。</p><h4 id="1-1-一致性Hash"><a href="#1-1-一致性Hash" class="headerlink" title="1.1 一致性Hash"></a>1.1 一致性Hash</h4><p>一致性哈希算法在1997年由麻省理工学院的Karger等人在解决分布式Cache中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得DHT可以在P2P环境中真正得到应用。</p><p>但现在一致性hash算法在分布式系统中也得到了广泛应用，研究过memcached缓存数据库的人都知道，memcached服务器端本身不提供分布式cache的一致性，而是由客户端来提供，具体在计算一致性hash时采用如下步骤：</p><ol><li><p>首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。</p></li><li><p>然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。</p></li><li><p>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。</p><p><img src="/images/image-figure_algorithm_1.png" alt="figure 1"></p><center>图一 一致性hash</center><p>从上图的状态中添加一台memcached服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在圆（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，如下图所示：</p><p><img src="/images/image-figure_algorithm_2.png" alt="figure 2"></p><center>图二 添加节点</center></li></ol><h4 id="1-2-DistKV的Hash流程"><a href="#1-2-DistKV的Hash流程" class="headerlink" title="1.2 DistKV的Hash流程"></a>1.2 DistKV的Hash流程</h4><p>一致性Hash的流程比较简单，但对于大数据存储来说，是有些不可接受的。在数据分片情况下，每一个Partition就代表着Hash环上的一个节点，如果采用传统的一致性Hash算法，一旦加入一个新的节点（Partition），那么那当用户get一个key的时候，因为之前这个key可能是被顺时针顺延打了节点4上面，但当新加入一个节点5时key就会打到节点5上，而很明显，这时候节点5并没有这些数据。</p><p>不过也不是没有办法去忽略这些影响，我们可以采用rehash，让受影响的那部分重新hash打到新的节点5上。</p><ol><li>首先所有Partition通过心跳从dmeta中获取全局视图。发现有新节点在hash环中，Partition4根据Partition5的位置判断得出自己需要将一部分数据迁移至Partition5.</li><li>Partition4中的follow节点中的建立对Partition5 leader的连接，并且对内部所有的kv在新的hash环上进行rehash，筛选出需要提交给Partition5的kv。</li><li>Partition4中的follow节点以原子的形式将每一个kv提交给Partition5.</li></ol><p>但是很明显，这个过程是一个很耗时的操作，会降低可用性（在kv转移的时候，这些kv是不可用的），并且在现实情况中，运行时横向扩展是不频繁的操作，一般项目构建初期，就会设计好预计所需要的数量级大小，因此为了可用性考虑，我们将这种操作做了进一步优化。</p><ol><li>当新Partition加入集群时，先不进行任何操作，在dmeta接受其心跳后，会增加一个hash环，和之前的hash环同时保存。</li><li>提醒所有客户端全局视图有更新，客户端拉取最新的全局视图。</li><li>客户端遍历同时使用多个hash环运行一致性hash算法，如果得到的结果不一致，就向两个不同的partition同时发起请求。如果这个请求是写请求，则只需要向最新的hash环提交。</li></ol><p>这种方式是我们通过实践观察得出，大多数用户其实没有运行时扩容的需求，并且一般运行时更需要可用性，对于用户来说，延迟因为是并行执行，因此也不会出现过大的增幅，不过我们也未在更大数据量和并发量上面进行测试，但预计可以接受。</p><h3 id="2-单机存储引擎"><a href="#2-单机存储引擎" class="headerlink" title="2. 单机存储引擎"></a>2. 单机存储引擎</h3><p>在数据库领域，一般性能优化一方面在于分布式架构，另一方面就在于单机存储引擎，我们目前在使用的就是JDK所提供的ConcurrentSkipListMap，虽然能够提供了排序的能力（为支持大数据表做支撑），但是明显对于一般场景下，这种其实是没有必要的，因此我们也提供了一个高效的hashMap实现，这种专用于不需要table服务，但能很明显提高性能。</p><h4 id="2-1-表结构的支持"><a href="#2-1-表结构的支持" class="headerlink" title="2.1 表结构的支持"></a>2.1 表结构的支持</h4><p>这里我们参考的是TIDB对Table的实现，详细可以看引用页TIDB的论文，首先假设我们有这样一个表的定义：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">User</span> &#123;</span><br><span class="line">ID <span class="type">int</span>,</span><br><span class="line">Name <span class="type">varchar</span>(<span class="number">20</span>),</span><br><span class="line">Role <span class="type">varchar</span>(<span class="number">20</span>),</span><br><span class="line">Age <span class="type">int</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (ID),</span><br><span class="line">Key idxAge (age)</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>SQL 和 KV 结构之间存在巨大的区别，那么如何能够方便高效地进行映射，就成为一个很重要的问题。一个好的映射方案必须有利于对数据操作的需求。那么我们先看一下对数据的操作有哪些需求，分别有哪些特点。</p><p>对于一个 Table 来说，需要存储的数据包括三部分：</p><ol><li>表的元信息</li><li>Table 中的 Row</li><li>索引数据</li></ol><p>表的元信息可以通过专门的冗余数据结构实现，这里不过多展开，对于 Row，可以选择行存或者列存，这两种各有优缺点。我们采用的是行存储的方式。</p><p>分析完需要存储的数据的特点，我们再看看对这些数据的操作需求，主要考虑 Insert/Update/Delete/Select 这四种语句。</p><p>对于 Insert 语句，需要将 Row 写入 KV，并且建立好索引数据。</p><p>对于 Update 语句，需要将 Row 更新的同时，更新索引数据（如果有必要）。</p><p>对于 Delete 语句，需要在删除 Row 的同时，将索引也删除。</p><p>上面三个语句处理起来都很简单。对于 Select 语句，情况会复杂一些。首先我们需要能够简单快速地读取一行数据，所以每个 Row 需要有一个 ID （显示或隐式的 ID）。其次可能会读取连续多行数据，比如 <code>Select * from user;</code>。最后还有通过索引读取数据的需求，对索引的使用可能是点查或者是范围查询。查询的时候有两种模式，一种是点查，比如通过 Primary Key 或者 Unique Key 的等值条件进行查询，如 <code>select name from user where id=1;</code> ，这种需要通过索引快速定位到某一行数据；另一种是 Range 查询，如 <code>select name from user where age &gt; 30 and age &lt; 35;</code>，这个时候需要通过<code>idxAge</code>索引查询 age 在 30 和 35 之间的那些数据。Index 还分为 Unique Index 和 非 Unique Index，这两种都需要支持。</p><p>大致的需求已经分析完了，因为我们有一个Partition内有序的分布式 Key-Value 引擎。这一点重要，可以帮助我们解决不少问题。比如对于快速获取一行数据，假设我们能够构造出某一个或者某几个 Key，定位到这一行，我们就能利用Store Server提供的 Seek 方法快速定位到这一行数据所在位置。再比如对于扫描全表的需求，如果能够映射为一个 Key 的 Range，从 StartKey 扫描到 EndKey，那么就可以简单的通过这种方式获得全表数据。操作 Index 数据也是类似的思路。</p><p>DistKV 对每个表分配一个 TableID，每一个索引都会分配一个 IndexID，每一行分配一个 RowID（如果表有整数型的 Primary Key，那么会用 Primary Key 的值当做 RowID），其中 TableID 在整个集群内唯一，IndexID/RowID 在表内唯一，这些 ID 都是 int64 类型。</p><p>每行数据按照如下规则进行编码成 Key-Value pair：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: tablePrefix&#123;tableID&#125;_recordPrefixSep&#123;rowID&#125;</span><br><span class="line">Value: [col1, col2, col3, col4]</span><br></pre></td></tr></table></figure><p>其中 Key 的 <code>tablePrefix</code>/<code>recordPrefixSep</code> 都是特定的字符串常量，用于在 KV 空间内区分其他数据。</p><p>对于 Index 数据，会按照如下规则编码成 Key-Value pair：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: tablePrefix&#123;tableID&#125;_indexPrefixSep&#123;indexID&#125;_indexedColumnsValue</span><br><span class="line">Value: rowID</span><br></pre></td></tr></table></figure><p>Index 数据还需要考虑 Unique Index 和非 Unique Index 两种情况，对于 Unique Index，可以按照上述编码规则。但是对于非 Unique Index，通过这种编码并不能构造出唯一的 Key，因为同一个 Index 的 <code>tablePrefix&#123;tableID&#125;_indexPrefixSep&#123;indexID&#125;</code> 都一样，可能有多行数据的 <code>ColumnsValue</code> 是一样的，所以对于非 Unique Index 的编码做了一点调整：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: tablePrefix&#123;tableID&#125;_indexPrefixSep&#123;indexID&#125;_indexedColumnsValue_rowID</span><br><span class="line">Value: null</span><br></pre></td></tr></table></figure><p>这样能够对索引中的每行数据构造出唯一的 Key。 注意上述编码规则中的 Key 里面的各种 xxPrefix 都是字符串常量，作用都是区分命名空间，以免不同类型的数据之间相互冲突，定义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var(</span><br><span class="line">tablePrefix     = &#x27;t&#x27;</span><br><span class="line">recordPrefixSep = &quot;_r&quot;</span><br><span class="line">indexPrefixSep  = &quot;_i&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>因为我们在Store Server内部的SkipListMap是通过字典序排列的，因此只需要按照我们设定的方式小心写入即可。</p><h4 id="2-2-Swiss-Map"><a href="#2-2-Swiss-Map" class="headerlink" title="2.2 Swiss Map"></a>2.2 Swiss Map</h4><p>上述表结构的实现其实是基于有序的存储引擎，但就如同前文所言，其实很多情况下，业务用不到table，那么我们如果采用全局hash的方式写入和读取，就会使得整体性能快上不少。</p><p>这里主要参考google的swiss Map来实现，使用到了X86_64CPU所支持的SIMD指令集。</p><h5 id="2-2-1-SIMD"><a href="#2-2-1-SIMD" class="headerlink" title="2.2.1 SIMD"></a>2.2.1 SIMD</h5><p>SIMD，即Single Instruction, Multiple Data，一条指令操作多个数据．是CPU基本指令集的扩展．主要用于提供fine grain parallelism，即小碎数据的并行操作．比如说图像处理，图像的数据常用的数据类型是RGB565, RGBA8888, YUV422等格式，这些格式的数据特点是一个像素点的一个分量总是用小于等于８bit的数据表示的．如果使用传统的处理器做计算，虽然处理器的寄存器是32位或是64位的，处理这些数据确只能用于他们的低８位，似乎有点浪费．如果把64位寄存器拆成８个８位寄存器就能同时完成８个操作，计算效率提升了８倍．SIMD指令的初衷就是这样的，只不过后来慢慢cover的功能越来越多．</p><h4 id="2-2-2-SwissMap概述"><a href="#2-2-2-SwissMap概述" class="headerlink" title="2.2.2 SwissMap概述"></a>2.2.2 SwissMap概述</h4><p><img src="/images/image-figure_algorithm_3.png" alt="figure 3"></p><center>图三 SwissMap 元数据</center><p><img src="/images/image-figure_algorithm_4.png" alt="figure 4"></p><center>图四 SwissMap指针空间</center><p>将16个键值对划分为一组，也可以把这个组叫做桶，存放在逻辑连续的线性地址空间内。(哈希函数计算的64位哈希值的前57位)/(哈希表的容量)计算出某个key对应的桶，如果桶内存在空闲或者键值对被删除的槽位，就可以将该键值对存放在这个位置里，否则顺序存放到下一个桶内。每个槽位都有一个字节的元数据与之对应，当元数据为000000的时候，表示该槽位是空的，11111110表示该槽位上的元素被删除了，否则该槽位存在一个元素，其对应的元数据的首位为1，剩下的七位为第二个哈希函数计算出来的值。</p><h5 id="2-2-2-1-为什么需要一个字节的元数据"><a href="#2-2-2-1-为什么需要一个字节的元数据" class="headerlink" title="2.2.2.1 为什么需要一个字节的元数据"></a>2.2.2.1 为什么需要一个字节的元数据</h5><p>元数据被用来快速检索，可以通过SIMD(单指令多数据)指令通过位运算快速判断组内是否存在空闲元素，或者已经满了, 以及匹配第二个哈希码计算出来的七位元数据相匹配的槽位。16 x 8 = 124bit,能够放入L1缓存，所以是缓存友好的。</p><h5 id="2-2-2-2-哈希冲突"><a href="#2-2-2-2-哈希冲突" class="headerlink" title="2.2.2.2 哈希冲突"></a>2.2.2.2 哈希冲突</h5><p>哈希表通过空间换时间，只要选择的hash函数足够好，计算出来的哈希值分布均匀，那么某个元素应为哈希冲突，需要存储到下一个桶的情况应该很少。</p><h5 id="2-2-2-3查询数据"><a href="#2-2-2-3查询数据" class="headerlink" title="2.2.2.3查询数据"></a>2.2.2.3查询数据</h5><ol><li><p>先通过第一个函数计算出哈希值，找到桶的位置</p></li><li><p>然而计算第二个哈希函数，找到桶内匹配该哈希值的槽位。找不到就继续从下一个桶找，指导发现一个空的槽位或者被删除的槽位。</p></li><li><p>找到的槽位对应的索引就是对应键值对指针在指针数组中的索引。然后通过找到的索引值找到key，value值。</p></li></ol><h5 id="2-2-2-4-Resize"><a href="#2-2-2-4-Resize" class="headerlink" title="2.2.2.4 Resize"></a>2.2.2.4 Resize</h5><p>当扩容过程中，我们没有必要冻结整个hashmap。假设一个hashmap的容量是64, 某个key扩容前所在桶是第28个桶，那么扩容一倍后对应的桶，可能仍然是28，也可能是92，但就只有这两种情况。在扩容过程中， 可以通过额外查询一次来确保获得值，直到扩容完成。但另一个挑战在于如果使用异步扩容，如何避免完全不用锁呢？因为如果扩容是异步的，必然由另一个线程来完成，那么resize的线程可能和执行插入，查询的线程由不同的CPU来执行，访问不同CPU的缓存。由于缓存不会立即更新到主存，主存的数据也不一定立即更新到另一个缓存，所以不同CPU会读到不一致的数据。但是如果加锁势必影响性能。</p><h5 id="2-2-2-4-非堆数据存储"><a href="#2-2-2-4-非堆数据存储" class="headerlink" title="2.2.2.4 非堆数据存储"></a>2.2.2.4 非堆数据存储</h5><p>由于Java直接内存分配速度限制，频繁使用Unsafe来分配直接内存是不可取的。所以每次分配相对较大的内存块 <code>Block</code> ，并且使用 <code>BlockPool</code> 来预分配内存。 <code>Block</code> 的大小应该是内存页的倍数，这样做的原因可能有两个，一是内存对齐，二是内存不足时，swap友好。</p><p><strong>1) 如何存储定长数据</strong></p><p>如果数据长度已知，我们直接可以使用偏移量来定位数据所在位置，并且支持原地更新。</p><p><strong>2) 如何存储变长数据</strong></p><p><img src="/images/image-figure_algorithm_5.png" alt="Untitled Diagram.png"></p><p>变长数据则需要额外的int类型的元数据来定位变长数据的起始位置和长度。元数据从数组的起始位置开始存，变长数据从数组的结束位置开始存，这样做的好处是我们能够很快的找到当前数组中第n个元素的起始位置。此外，第n-1个元素的起始位置减去1，就是当前元素的结束位置。如果n是第一个元素，那么当前元素的结束位置就是数组的末尾。</p><p><strong>3) 内存回收</strong></p><p>对于变长元素数据，由于并不总是能原地更新，以及出于效率考虑，我们更新数据的时候总是插入一个新的数据，然后修改对应的指针到指向新的数据。这时候，内存回收就会是一个问题。在这里我们可以考虑使用位图索引来记录被删除的元素，如果删除的元素过多，可以考虑合并block。具体如何合并仍然存在挑战。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-Algorithm和Data-struct&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-Algorithm和Data-struct&quot; class=&quot;headerlink&quot; title=&quot;基于</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（6）-MetaServer</title>
    <link href="https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Meta%20Server/"/>
    <id>https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Meta%20Server/</id>
    <published>2021-05-21T16:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-MetaServer"><a href="#基于Raft协议的NoSQL数据库的设计和实现-MetaServer" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-MetaServer"></a>基于Raft协议的NoSQL数据库的设计和实现-MetaServer</h2><p>前面我们提到，Meta Server 主要有这几个功能：</p><ol><li>管理监控所有节点。</li><li>给出交互接口。</li></ol><p>那接下来详细介绍一下每个功能是如何实现的。</p><h3 id="1-监控管理Store-Server功能"><a href="#1-监控管理Store-Server功能" class="headerlink" title="1. 监控管理Store Server功能"></a>1. 监控管理Store Server功能</h3><p>我们之所以要管理监控Store Server，是需要管理Store Process 的存亡，动态拉起注册一个节点或者重启原本节点，使得整个系统处于最大可用状态。因此从技术层面需要做两件事情：</p><h4 id="1-1-实时获取更新所有节点的存活状态"><a href="#1-1-实时获取更新所有节点的存活状态" class="headerlink" title="1.1 实时获取更新所有节点的存活状态"></a>1.1 实时获取更新所有节点的存活状态</h4><p>这个功能我将其拆分为三个问题，首先是如何实时更新？这个我们通过心跳机制来做到。在每个节点上，我们需要配置对应Meta Server集群的地址，以每隔20ms的频率向Meta Server推送当前节点的状态。</p><p><img src="/images/image-figure_meta_1.png" alt="figure 1"></p><center>图一 Meta Server心跳</center><p>第二个问题是如何高可用存储节点状态数据，这个问题就比较困难了，因为Meta Server是有状态的服务，为了保证其高可用，我们采用raft的方式去使得这部分数据能够同步冗余，一旦leader节点宕机，follower节点也可以立刻服务。</p><p>第三个问题是数据结构的问题，因为Partition，node（character），shard，这些信息都是一级一级嵌套的，因此我们采用了类似zookeeper的目录式结构，但这样也会有一些问题。比如：如果我们不做冗余的索引，当我在查询某几个节点的存活状态时就需要遍历，这会导致时间开销，但如果使用索引，又会导致需要同步索引等问题增加复杂性。因此在未来，我们也将考虑将其底层改为支持sql的KV式的存储引擎。</p><h4 id="1-2设计节点重启和加入时的策略"><a href="#1-2设计节点重启和加入时的策略" class="headerlink" title="1.2设计节点重启和加入时的策略"></a>1.2设计节点重启和加入时的策略</h4><p>节点一般在以下三种情况下会需要这个策略：</p><ol><li>节点宕机重启。</li><li>新节点加入已有的partition</li><li>新节点加入新partition</li></ol><p>第一种情况下，我们只需要判断当心跳延时10s未发送时则判断该节点死亡，该节点下的所有shard也判为死亡。这时候就需要向节点所在服务器发送信号通知重启进程或通知管理员重启机器。而raft自带的snapshot和日志复制策略可以使得重启后的进程能够追上partition集群内其他节点的进度。</p><p>第二种情况和第一种类似，SOFA-JRAFT支持动态注册新节点到raft集群内，因此我们只需要实现相关的接口即可。partition加入新节点时，集群内部会向原来raft集群通知，然后raft集群会修改集群状态机接纳新节点，并且向新节点同步数据。</p><p>第三种情况涉及到新的partition，在我们的方案中，则需要新增一个hash环或整体进行rehash。详情参考算法篇。</p><h3 id="2-交互接口"><a href="#2-交互接口" class="headerlink" title="2. 交互接口"></a>2. 交互接口</h3><p>client方面，一方面dmeta client要为Store Server提供支持，提供心跳上报功能，另一方面，dmeta client也要为用户提供支持，用户需要获得全局信息Global View（主要是所有shard的信息）以获取哪个Key在哪个位置，我应该把这个key发送到哪个位置，这里也会在算法篇详细讲述。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-MetaServer&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-MetaServer&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计和实现-</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（5）-Partition和StoreServer</title>
    <link href="https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Partition%E5%92%8CStoreServer/"/>
    <id>https://kairbon.github.io/2021/05/21/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Partition%E5%92%8CStoreServer/</id>
    <published>2021-05-21T15:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-Partition和StoreServer"><a href="#基于Raft协议的NoSQL数据库的设计和实现-Partition和StoreServer" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-Partition和StoreServer"></a>基于Raft协议的NoSQL数据库的设计和实现-Partition和StoreServer</h2><p>在前文中，已经简单介绍了DistKV关于Partition和Store Server的部分内容。而这部分我们主要将我们在CAP方面的妥协。讲述为什么DistKV的一致性强于Redis，性能弱于Redis。</p><h3 id="1-一致性"><a href="#1-一致性" class="headerlink" title="1. 一致性"></a>1. 一致性</h3><p>首先在讲一致性前，先说明我们对比的维度。在通常用户使用kv的增删查改过程中，涉及到同时读，先写后读，先读后写，写后写，在分布式环境下，是否能够保持时序一致。</p><p>通常情况下，大部分公司使用的是Redis Sentinel 模式，普通的主从备份，订阅发布的模式由于主节点一旦宕机就会导致不可用这种方式目前基本不作为线上系统的常用模式。因此我们，就拿Redis Sentinel模式与Distkv进行对比。</p><p>Redis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了Redis的高可用问题。</p><p>但是这套模式有个问题就是对于横向扩展的支持，最大的存储量受限于单机最大存储量。Redis3.0的cluster模式解决了这个问题，但是却又带来了新的问题，就是分片的一致性降低。</p><h4 id="1-1-数据丢失"><a href="#1-1-数据丢失" class="headerlink" title="1.1 数据丢失"></a>1.1 数据丢失</h4><p>那么为什么一致性会降低呢？在Redis的分片中，采用的策略是最基本的主从同步，Redis主从同步都是通过异步的方式去同步。而当主节点收到一些请求而这些请求还未收到从节点的确认时主节点出现宕机，即使流量瞬间切换到了从节点，也会导致数据丢失，造成不一致。</p><p>然而对于DistKV来说就没有这种情况，在DistKV中，分片内部采用raft作为一致性协议，下图模拟这种情况下raft的实现：</p><p><img src="/images/image-figure_partition_1.png" alt="figure 1"></p><center>图一 日志写入</center><p>和Redis不同，当raft集群中，leader收到来自client的请求后，会同步向follower同步日志，而这个过程中，如果失败，可以向client返回写入失败。在同步的过程中，如果主节点宕机，客户端也会直接出错，而不会得到错误提示。</p><p>因为在Raft中采用同步日志复制的方式提高一致性，而Redis使用了异步的方式，虽然提升了性能（客户端延迟），但是却降低了数据一致性。</p><h4 id="1-2-线性一致性"><a href="#1-2-线性一致性" class="headerlink" title="1.2 线性一致性"></a>1.2 线性一致性</h4><p>在讲线性一致性前，可以通过图二来看一个显示情况。</p><p><img src="/images/image-figure_partition_2.png" alt="figure 2"></p><center>图二 最终一致性</center><ol><li>Referee：更新比赛的最终结果，先 insert 到数据库 leader 副本，然后 Leader 再复制给两个 Follower 副本</li><li>Alice：从 Follower 1 中查到了最新的比赛分数</li><li>Bob：从 Follower 2 中确没查到最新的比赛分数，确显示比赛正在进行</li></ol><p>图二展示的情况就是最终一致性，属于一致性要求里面最低的，<strong>一致性其实主要是描述了在故障和延迟的情况下副本间的状态协调的问题</strong></p><p><img src="/images/image-figure_partition_3.png" alt="figure 3"></p><center>图三 线性一致性</center><p>图三展示了线性一致性的系统在应对相同场景下的情况。在Redis分布式下，采用的是图二的方式，这种会明显提升性能，但却损失了一致性，而对于DistKV来说，使其符合线性一致性是我们和Redis不同的地方，而这种区别也决定了许多，比如我们可以在DistKV上很轻松的支持事务操作，而对于Redis则需要额外的辅助工作。</p><h3 id="2-多线程模型"><a href="#2-多线程模型" class="headerlink" title="2. 多线程模型"></a>2. 多线程模型</h3><p>在前面我们讲到了DistKV在多线程提升性能方面遇到的问题：</p><ol><li>对于key的存取会存在竞争</li><li>线程等待导致延时过高</li></ol><p>最终我们采用异步RPC Server + 无锁队列实现高性能线程安全的store。本方案依赖异步rpc server的能力，且整个过程是没有资源竞争的，也就是不需要对MAP的读取加任何锁。</p><p><img src="/images/image-figure_3.png" alt="figure 3"></p><center>图三 方案架构图</center><p>设计n个工作线程，每个工作线程拥有一个与之对应的queue和一个SkipListMap，每个独立的存取线程和内部保存的数据被我们称之为Shard。rpc services会将请求post到不同的queue中，然后worker thread会从queue中fetch request来执行(类似于生产者消费者)。rpc services根据一些策略来决定将request投递到哪个queue中，但不管怎样必须保证，对于同一个key的所有requests，必须投递到同一个queue中,也就是我们保证同一个key的所有requests必须在同一个线程执行，这样就不会有任何的race condition。</p><p>当worker thread拿到一个request时，他会解析request并且做对应的执行，执行完之后，需要产生结果给io thread进行返回。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-Partition和StoreServer&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-Partition和StoreServer&quot; class=&quot;headerlink&quot; title=&quot;基于</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（4）-Architecture</title>
    <link href="https://kairbon.github.io/2021/05/17/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Architecture/"/>
    <id>https://kairbon.github.io/2021/05/17/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Architecture/</id>
    <published>2021-05-17T10:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-Architecture"><a href="#基于Raft协议的NoSQL数据库的设计和实现-Architecture" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-Architecture"></a>基于Raft协议的NoSQL数据库的设计和实现-Architecture</h2><p>DistKV有着独特的架构，这使得它在一致性方面的能力尤其出色。如图一</p><p><img src="/images/image-figure_1.png" alt="figure 1"></p><center>图一 DistKV 分布式架构</center><h3 id="1-Store-Server"><a href="#1-Store-Server" class="headerlink" title="1. Store Server"></a>1. Store Server</h3><p>在DistKV中，将存储的数据分为无数可横向扩展的Partition，每组Partitation内部都保留着与其他Partition不同的数据。因为每个Partition都保存着唯一的一份数据，因此需要一些容灾策略来保证数据的可用性。我们采用一组Raft集群来做到这点，每当有DML来修改此分片的数据状态时，Raft将会把操作同步执行到每一个机器上。</p><h4 id="1-1-数据模型"><a href="#1-1-数据模型" class="headerlink" title="1.1 数据模型"></a>1.1 数据模型</h4><p>因为DistKV是KV数据库，我们采用Map作为我们的底层数据结构。并且考虑到后期会增加range查询的功能，我们使用跳表作为Map的实现方式。</p><h5 id="1-1-1-跳表"><a href="#1-1-1-跳表" class="headerlink" title="1.1.1 跳表"></a>1.1.1 跳表</h5><p>跳表全称为跳跃列表，它允许快速查询，插入和删除一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是O(logn)。快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集（见图二）。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。</p><p><img src="/images/image-figure_2.png" alt="figure 2"></p> <center>图二 跳表</center><p>这种结构有几个特点是Distkv最需要的：</p><ol><li>全局有序，这对于Range来说是非常必要的。</li><li>时间开销小，对于内存式数据库来说，效率是非常关键的。</li></ol><h4 id="1-2-多线程模型"><a href="#1-2-多线程模型" class="headerlink" title="1.2 多线程模型"></a>1.2 多线程模型</h4><h4 id="1-2-1-历史"><a href="#1-2-1-历史" class="headerlink" title="1.2.1 历史"></a>1.2.1 历史</h4><p>一开始Store Server采用多线程+读写锁的方式来保证读写的正常和数据的一致性，但很快我们就遇到了读写性能上的瓶颈。主要原因就是多线程对锁的争抢，Map只有一个，每一次读写就需要获得锁。因此我们采用了一种和RPC多线程结合的方式，来解决以下两个问题：</p><ol><li>对于key的存取会存在竞争</li><li>线程等待导致延时过高</li></ol><h4 id="1-2-2-多线程模型"><a href="#1-2-2-多线程模型" class="headerlink" title="1.2.2 多线程模型"></a>1.2.2 多线程模型</h4><p>最终我们采用异步RPC Server + 无锁队列实现高性能线程安全的store。本方案依赖异步rpc server的能力，且整个过程是没有资源竞争的，也就是不需要对MAP的读取加任何锁。</p><p><img src="/images/image-figure_3.png" alt="figure 3"></p><center>图三 方案架构图</center><p>设计n个工作线程，每个工作线程拥有一个与之对应的queue和一个SkipListMap，每个独立的存取线程和内部保存的数据被我们称之为Shard。rpc services会将请求post到不同的queue中，然后worker thread会从queue中fetch request来执行(类似于生产者消费者)。rpc services根据一些策略来决定将request投递到哪个queue中，但不管怎样必须保证，对于同一个key的所有requests，必须投递到同一个queue中,也就是我们保证同一个key的所有requests必须在同一个线程执行，这样就不会有任何的race condition。</p><p>当worker thread拿到一个request时，他会解析request并且做对应的执行，执行完之后，需要产生结果给io thread进行返回。</p><h3 id="2-Meta-Server"><a href="#2-Meta-Server" class="headerlink" title="2. Meta Server"></a>2. Meta Server</h3><p>因为存在许多分片和集群，那如何集中式的管理这些分片和每一个节点就成为了一个难题。我们将管理分片，订阅，发布，监控节点的功能作为一个独立的运行时组件抽离了出来。</p><p>从技术角度讲，Meta Server需要解决以下几个问题：</p><ol><li>DistKV Store Process即时向Meta Server注册，Meta Server监控DistKV Store Process的状态。</li><li>为每一个注册到Meta Server的DistKV Store process中的shard分配一个partitionID, nodeID, 和shardID。通过检测 DistKV Store process 的健康状况来判断shard存亡，并即时更新路由表。</li><li>当Dist Store进程挂掉要即时更新路由表，并且将载有挂掉的Dist Store进程数据的Dist Store进程的路由表和原路由表合并或更新。</li><li>DistKV Client首先从Meta Server获取全局路由表, 然后用户提供shardID来获取DistKV Store process的location的服务。(Client利用cache优化这个过程)</li><li>使用Raft来保证持有数据和服务的可用性</li></ol><p>从实现层面，我们采用蚂蚁集团开源的SOFA-JRAFT来作为集群同步时的Raft算法的实现组件。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-Architecture&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-Architecture&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（3）-Raft</title>
    <link href="https://kairbon.github.io/2021/05/17/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Raft/"/>
    <id>https://kairbon.github.io/2021/05/17/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-Raft/</id>
    <published>2021-05-17T10:52:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-Raft"><a href="#基于Raft协议的NoSQL数据库的设计和实现-Raft" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-Raft"></a>基于Raft协议的NoSQL数据库的设计和实现-Raft</h2><h3 id="1-Raft的历史"><a href="#1-Raft的历史" class="headerlink" title="1.  Raft的历史"></a>1.  Raft的历史</h3><p>所有共识算法都是由一个基本的问题出发的，就是拜占庭将军问题：拜占庭将军问题是一个协议问，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：欺骗某些将军采取进攻行动；促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；或者迷惑某些将军，使他们无法做出决定。如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利。</p><p>拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或断开以及遭到恶意攻击，计算机和网络可能出现不可预料的行为。</p><p>基于这个问题，Google给出了自己的解法，就是Paxos算法，但这种算法过于复杂且难以实现。然而在真实的云计算环境下，“欺骗将军”这一过程是几乎是不太可能实现的，因此为了简化Paxos算法，斯坦福大学提出了一种新的分布式一致性算法Raft算法，这种算法巧妙且易于理解的解决了这个问题。</p><h3 id="2-算法过程"><a href="#2-算法过程" class="headerlink" title="2. 算法过程"></a>2. 算法过程</h3><p>在Raft中，任何时候一个服务器可以扮演下面角色之一：</p><ol><li>Leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader。</li><li>Follower: 类似选民，完全被动。</li><li>Candidate候选人: 类似Proposer律师，可以被选为一个新的领导人。</li></ol><p>Raft阶段分为两个，首先是选举过程，然后在选举出来的领导人带领进行正常操作，比如日志复制等。下面用图示展示这个过程：</p><ol><li><p>任何一个服务器都可以成为一个候选者Candidate，它向其他服务器Follower发出要求选举自己的请求：</p><p><img src="/images/image-figure_raft_1.png" alt="raft_1"></p><center>图一 Raft选举 1</center><ol start="2"><li>其他服务器同意了，发出OK。</li></ol><p><img src="/images/image-figure_raft_2.png" alt="raft 2"></p><center>图二 Raft选举 2</center><p>注意如果在这个过程中，有一个Follower宕机，没有收到请求选举的要求，因此候选者可以自己选自己，只要达到N/2 + 1 的大多数票，候选人还是可以成为Leader的</p><p>成为leader后，leader节点就会接受外部请求从而改变状态机的状态，并且将日志复制到其他Follower节点上。</p><ol start="3"><li>以后通过心跳来监控节点状态和作为日志复制的通知。<img src="/images/image-figure_raft_3.png" alt="raft 3"></li></ol><center>图三 Raft选举 3</center><ol start="4"><li><p>如果一旦这个Leader当机崩溃了，那么Follower中有一个成为候选者，发出邀票选举。</p><p><img src="/images/image-figure_raft_4.png" alt="raft 4"></p><center>图四 宕机</center><p>Follower同意后，其成为Leader，继续承担日志复制等指导工作。</p><p>值得注意的是，整个选举过程是有一个时间限制的，如图五：</p><p><img src="/images/image-figure_raft_5.png" alt="raft 5"></p><center>图五 选举</center></li></ol></li></ol><p>   Splite Vote是因为如果同时有两个候选人向大家邀票，这时通过类似加时赛来解决，两个候选者在一段timeout比如300ms互相不服气的等待以后，因为双方得到的票数是一样的，一半对一半，那么在300ms以后，再由这两个候选者发出邀票，这时同时的概率大大降低，那么首先发出邀票的的候选者得到了大多数同意，成为领导者Leader，而另外一个候选者后来发出邀票时，那些Follower选民已经投票给第一个候选者，不能再投票给它，它就成为落选者了，最后这个落选者也成为普通Follower一员了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-Raft&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-Raft&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计和实现-Raft&quot;&gt;&lt;/a&gt;基于</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（2）-History</title>
    <link href="https://kairbon.github.io/2021/05/11/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-History/"/>
    <id>https://kairbon.github.io/2021/05/11/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-History/</id>
    <published>2021-05-11T16:58:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现-History"><a href="#基于Raft协议的NoSQL数据库的设计和实现-History" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现-History"></a>基于Raft协议的NoSQL数据库的设计和实现-History</h2><h2 id="1-分布式存储系统"><a href="#1-分布式存储系统" class="headerlink" title="1. 分布式存储系统"></a>1. 分布式存储系统</h2><p>传统的集中式存储，主要采用存储区域网络（Storage Area Network，简称SAN）和网络附属存储（Network Attached Storage，简称NAS）。但是随着企业业务的高速发展和存储规模的扩大，这些传统集中式存储逐渐暴露出了维护成本高昂，可用性不高，热点等许多问题，除此之外，因为存储是集中式的方式，所以如果宕机，那么依赖它的一切服务都将会出现问题。当然解决这些可用性问题，业界也有许多方式。从硬件层面的有通过使用RAID，ZFS等技术来防止单磁盘故障导致的不可用，还有比如建设专用的存储数据中心，冗余电源等各种方式来提升其可用性。但这些都无疑使得存储单元的成本上升。</p><p>目前，无数工业界和研究界的目光都投射到分布式存储系统上面去解决大规模数据存储的问题。这个原因一方面是随着pc机变得越来越便宜，使得存储使用大规模计算集群成为可能，另一方面随着云计算的火热，各大云计算厂商都在拼命降低用户使用计算资源的成本，使得分布式存储变为企业数据存储的首要选择。</p><p>Oracle和SQL Server作为传统企业级大型关系型数据库，是之前大部分企业用户存储格式化数据首要的选择，然而其高昂的服务费和许多其他因素却使得许多企业不得不考虑更多问题。这时候，分布式NoSQL数据库像是一颗璀璨的新星从众多分布式存储架构中脱颖而出。这种数据库不仅解决了传统数据库遇到的性能和存储分配的问题，还有着极为优秀的可用性。例如Google的BigTable和Spanner，这些数据库结合分布式系统天生的抗单节点故障能力以及水平伸缩等特点，为大数据场景做了完美的支撑。</p><h2 id="2-NoSQL数据库"><a href="#2-NoSQL数据库" class="headerlink" title="2. NoSQL数据库"></a>2. NoSQL数据库</h2><p>目前在国内外大规模使用并且效果比较好的NoSQL数据库主要有Google的Spanner，Redis。这些系统每一种都经历了无数工业界的检验，尤其是Redis，支撑新浪微博的热点资讯，扛过了每秒几千万的流量，足以证明NoSQL数据库在工业界的实力。而对于NoSQL数据库本身来说，不仅在架构上做到高可用，高容错，一致性。通常也使用自己的API，来实现对数据本身的增删查改。下面就以Redis为例，讲述NoSQL数据库的特性。而本论文主要也是和Redis做对比。</p><h3 id="2-1-Redis"><a href="#2-1-Redis" class="headerlink" title="2.1 Redis"></a>2.1 Redis</h3><p>一开始，Redis是由出生于西西里岛的意大利人（Antirez）编写的，但到目前，Redis已经成为了阿里巴巴，腾讯等众多互联网一线大厂广泛使用的分布式内存数据库组件，主要用于缓存，队列，排行榜等众多Web功能的使用场景。Redis在中国互联网中有着广泛的使用经验。但在实际使用场景中我们又通常会遇到数据丢失，服务不可用，一致性不足以支撑业务等问题。</p><p>而本文提出并实现一种，有着和Redis好用易于上手的DSL以及Client，并且解决了Redis在大数据场景下的一些问题的基于键值对的分布式内存NoSQL数据库-DistKV。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现-History&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现-History&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计和实现-Histor</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>基于Raft协议的NoSQL数据库的设计和实现（1）-简介</title>
    <link href="https://kairbon.github.io/2021/05/11/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-%E7%AE%80%E4%BB%8B/"/>
    <id>https://kairbon.github.io/2021/05/11/%E5%9F%BA%E4%BA%8ERaft%E5%8D%8F%E8%AE%AE%E7%9A%84NoSql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%AE%9E%E7%8E%B0-%E7%AE%80%E4%BB%8B/</id>
    <published>2021-05-11T16:58:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于Raft协议的NoSQL数据库的设计和实现"><a href="#基于Raft协议的NoSQL数据库的设计和实现" class="headerlink" title="基于Raft协议的NoSQL数据库的设计和实现"></a>基于Raft协议的NoSQL数据库的设计和实现</h2><h3 id="1-论文简介"><a href="#1-论文简介" class="headerlink" title="1. 论文简介"></a>1. 论文简介</h3><p>近些年来，随着大数据业务和巨型Web网站的增多，如何存储和管理各种数据成为了各大公司棘手的难题。为了存储日益增加的用户个人数据和业务数据，能够灵活简单使用，高可用的，使用简便的NoSQL数据库在工业界的使用越来越多。本课题提出了一种基于Raft一致性协议的内存式NoSQL数据库（下称DistKV），并且支持表结构。本课题对当前NoSQL数据库使用上因为架构设计导致的丢数据，不可用，性能瓶颈等问题进行了探讨和优化，并且尤其对于大数据存储场景做出专项优化。</p><ol><li><p>设计实现DistKV的基本架构，考虑横向扩展，表结构存储等基本需求。</p></li><li><p>设计实现高性能专用RPC用于降低传输延时。</p></li><li><p>对于业务中使用NoSQL数据库遇到的丢数据，不可用问题做专项测试和比对。</p></li><li><p>和市面流行的NoSQL数据库在读写方面进行比对。</p></li></ol><p>本论文主要通过以下几个方面展开讲述本系统的设计。</p><ol><li>History</li><li>Raft</li><li>Architecture</li><li>Partition和StoreServer<ol><li>Multi-thread</li><li>Sync</li></ol></li><li>MetaServer<ol><li>Function</li><li>Optimization</li></ol></li><li>Algorithm和Data struct<ol><li>SkipList</li></ol></li><li>DRPC<ol><li>NIO</li><li>Multi-Thread</li><li>Code</li></ol></li><li>API<ol><li>DistKV Client</li><li>DRPC Client</li></ol></li><li>Benchmark</li><li>Conclusion</li><li>Acknowledgments</li><li>Reference</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于Raft协议的NoSQL数据库的设计和实现&quot;&gt;&lt;a href=&quot;#基于Raft协议的NoSQL数据库的设计和实现&quot; class=&quot;headerlink&quot; title=&quot;基于Raft协议的NoSQL数据库的设计和实现&quot;&gt;&lt;/a&gt;基于Raft协议的NoSQL数据库</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务-2pc,3pc</title>
    <link href="https://kairbon.github.io/2021/03/14/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-2pc-3pc/"/>
    <id>https://kairbon.github.io/2021/03/14/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-2pc-3pc/</id>
    <published>2021-03-14T11:09:56.000Z</published>
    <updated>2022-02-10T15:08:35.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分布式事务-2pc-3pc"><a href="#分布式事务-2pc-3pc" class="headerlink" title="分布式事务-2pc,3pc"></a>分布式事务-2pc,3pc</h2><p>原作者 <a href="https://www.cnblogs.com/qdhxhz/p/11167025.html">https://www.cnblogs.com/qdhxhz/p/11167025.html</a> </p><h3 id="1-2pc-two-phase-commit"><a href="#1-2pc-two-phase-commit" class="headerlink" title="1. 2pc(two phase commit)"></a>1. 2pc(two phase commit)</h3><p>两阶段提交又称2PC,2PC是一个非常经典的强一致、中心化的原子提交协议。</p><p>这里所说的中心化是指协议中有两类节点：一个是中心化协调者节点（coordinator）和N个参与者节点（partcipant）。<br>两个阶段：第一阶段：投票阶段 和第二阶段：提交/执行阶段。<br>举例 订单服务A，需要调用 支付服务B 去支付，支付成功则处理购物订单为待发货状态，否则就需要将购物订单处理为失败状态。</p><p>那么看2PC阶段是如何处理的</p><h4 id="1-1-第一阶段"><a href="#1-1-第一阶段" class="headerlink" title="1.1 第一阶段"></a>1.1 第一阶段</h4><p><img src="/images/pasted-9.png" alt="upload successful"><br>第一阶段主要分为3步</p><p>(1) 事务询问</p><p>协调者 向所有的 参与者 发送事务预处理请求，称之为Prepare，并开始等待各 参与者 的响应。</p><p>(2) 执行本地事务</p><p>各个 参与者 节点执行本地事务操作,但在执行完成后并不会真正提交数据库本地事务，而是先向 协调者 报告说：“我这边可以处理了/我这边不能处理”。.</p><p>(3) 各参与者向协调者反馈事务询问的响应</p><p>如果 参与者 成功执行了事务操作,那么就反馈给协调者 Yes 响应,表示事务可以执行,如果没有 参与者 成功执行事务,那么就反馈给协调者 No 响应,表示事务不可以执行。</p><p>第一阶段执行完后，会有两种可能。1、所有都返回Yes. 2、有一个或者多个返回No。</p><h4 id="1-2-第二阶段"><a href="#1-2-第二阶段" class="headerlink" title="1.2 第二阶段"></a>1.2 第二阶段</h4><p>第二阶段：提交/执行阶段（成功流程）成功条件：所有参与者都返回Yes。</p><p><img src="/images/pasted-10.png" alt="upload successful"><br>第二阶段主要分为两步</p><p>​ 1)所有的参与者反馈给协调者的信息都是Yes,那么就会执行事务提交</p><p>​ 协调者 向 所有参与者 节点发出Commit请求.</p><p>​ 2)事务提交</p><p>​ 参与者 收到Commit请求之后,就会正式执行本地事务Commit操作,并在完成提交之后释放整个事务执行期间占用的事务资源。</p><h4 id="1-3-第二阶段：提交-执行阶段（异常流程）"><a href="#1-3-第二阶段：提交-执行阶段（异常流程）" class="headerlink" title="1.3 第二阶段：提交/执行阶段（异常流程）"></a>1.3 第二阶段：提交/执行阶段（异常流程）</h4><p>异常条件：任何一个 参与者 向 协调者 反馈了 No 响应,或者等待超时之后,协调者尚未收到所有参与者的反馈响应。</p><p><img src="/images/pasted-11.png" alt="upload successful"></p><p>异常流程第二阶段也分为两步</p><p>1)发送回滚请求</p><p>​ 协调者 向所有参与者节点发出 RoollBack 请求.</p><p>​ 2)事务回滚</p><p>​ 参与者 接收到RoollBack请求后,会回滚本地事务。</p><h4 id="1-4-2PC缺点"><a href="#1-4-2PC缺点" class="headerlink" title="1.4 2PC缺点"></a>1.4 2PC缺点</h4><p>通过上面的演示，很容易想到2pc所带来的缺陷</p><p>1）性能问题</p><p>无论是在第一阶段的过程中,还是在第二阶段,所有的参与者资源和协调者资源都是被锁住的,只有当所有节点准备完毕，事务 协调者 才会通知进行全局提交，</p><p>参与者 进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。</p><p>2）单节点故障</p><p>由于协调者的重要性，一旦 协调者 发生故障。参与者 会一直阻塞下去。尤其在第二阶段，协调者 发生故障，那么所有的 参与者 还都处于</p><p>锁定事务资源的状态中，而无法继续完成事务操作。（虽然协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）</p><p>2PC出现单点问题的三种情况</p><p>(1)协调者正常,参与者宕机</p><p>​ 由于 协调者 无法收集到所有 参与者 的反馈，会陷入阻塞情况。</p><p>​ 解决方案:引入超时机制,如果协调者在超过指定的时间还没有收到参与者的反馈,事务就失败,向所有节点发送终止事务请求。</p><p>(2)协调者宕机,参与者正常</p><p>​ 无论处于哪个阶段，由于协调者宕机，无法发送提交请求，所有处于执行了操作但是未提交状态的参与者都会陷入阻塞情况.</p><p>​ 解决方案:引入协调者备份,同时协调者需记录操作日志.当检测到协调者宕机一段时间后，协调者备份取代协调者，并读取操作日志，向所有参与者询问状态。</p><p>(3)协调者和参与者都宕机</p><p>发生在第一阶段： 因为第一阶段，所有参与者都没有真正执行commit，所以只需重新在剩余的参与者中重新选出一个协调者，新的协调者在重新执行第一阶段和第二阶段就可以了。<br>2)发生在第二阶段 并且 挂了的参与者在挂掉之前没有收到协调者的指令。也就是上面的第4步挂了，这是可能协调者还没有发送第4步就挂了。这种情形下，新的协调者重新执行第一阶段和第二阶段操作。</p><p>3)发生在第二阶段 并且 有部分参与者已经执行完commit操作。就好比这里订单服务A和支付服务B都收到协调者 发送的commit信息，开始真正执行本地事务commit,但突发情况，Acommit成功，B确挂了。这个时候目前来讲数据是不一致的。虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了！ 2PC 无法解决这个问题。</p><h3 id="2-三阶段提交-3PC"><a href="#2-三阶段提交-3PC" class="headerlink" title="2. 三阶段提交(3PC)"></a>2. 三阶段提交(3PC)</h3><p>三阶段提交协议（3PC）主要是为了解决两阶段提交协议的阻塞问题，2pc存在的问题是当协作者崩溃时，参与者不能做出最后的选择。因此参与者可能在协作者恢复之前保持阻塞。三阶段提交（Three-phase commit），是二阶段提交（2PC）的改进版本。</p><p>与两阶段提交不同的是，三阶段提交有两个改动点。</p><p>1、 引入超时机制。同时在协调者和参与者中都引入超时机制。<br>2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。<br>也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。</p><h4 id="2-1-CanCommit阶段"><a href="#2-1-CanCommit阶段" class="headerlink" title="2.1 CanCommit阶段"></a>2.1 CanCommit阶段</h4><p>之前2PC的一阶段是本地事务执行结束后，最后不Commit,等其它服务都执行结束并返回Yes，由协调者发生commit才真正执行commit。而这里的CanCommit指的是 尝试获取数据库锁 如果可以，就返回Yes。</p><p>这阶段主要分为2步</p><p>事务询问 协调者 向 参与者 发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待 参与者 的响应。<br>响应反馈 参与者 接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No</p><h4 id="2-2-PreCommit阶段"><a href="#2-2-PreCommit阶段" class="headerlink" title="2.2 PreCommit阶段"></a>2.2 PreCommit阶段</h4><p>在阶段一中，如果所有的参与者都返回Yes的话，那么就会进入PreCommit阶段进行事务预提交。这里的PreCommit阶段 跟上面的第一阶段是差不多的，只不过这里 协调者和参与者都引入了超时机制 （2PC中只有协调者可以超时，参与者没有超时机制）。</p><h4 id="2-3-DoCommit阶段"><a href="#2-3-DoCommit阶段" class="headerlink" title="2.3 DoCommit阶段"></a>2.3 DoCommit阶段</h4><p>这里跟2pc的阶段二是差不多的。</p><h4 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h4><p>相比较2PC而言，3PC对于协调者（Coordinator）和参与者（Partcipant）都设置了超时时间，而2PC只有协调者才拥有超时机制。这解决了一个什么问题呢？</p><p>这个优化点，主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题，因为参与者自身拥有超时机制会在超时后，</p><p>自动进行本地commit从而进行释放资源。而这种机制也侧面降低了整个事务的阻塞时间和范围。</p><p>另外，通过CanCommit、PreCommit、DoCommit三个阶段的设计，相较于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。</p><p>以上就是3PC相对于2PC的一个提高（相对缓解了2PC中的前两个问题），但是3PC依然没有完全解决数据不一致的问题。</p><p>参考<br>1、分布式事务：深入理解什么是2PC、3PC</p><p>2、分布式事务、3pc</p><p>3、对分布式事务及两阶段提交、三阶段提交的理解</p><p>4、分布式理论基础：2PC和3PC</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;分布式事务-2pc-3pc&quot;&gt;&lt;a href=&quot;#分布式事务-2pc-3pc&quot; class=&quot;headerlink&quot; title=&quot;分布式事务-2pc,3pc&quot;&gt;&lt;/a&gt;分布式事务-2pc,3pc&lt;/h2&gt;&lt;p&gt;原作者 &lt;a href=&quot;https://www.c</summary>
      
    
    
    
    
    <category term="分布式系统" scheme="https://kairbon.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ自学（对比kafka）---旧文章搬运</title>
    <link href="https://kairbon.github.io/2021/02/08/RocketMQ%E8%87%AA%E5%AD%A6/"/>
    <id>https://kairbon.github.io/2021/02/08/RocketMQ%E8%87%AA%E5%AD%A6/</id>
    <published>2021-02-08T12:19:20.000Z</published>
    <updated>2022-02-10T15:08:35.121Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RocketMQ自学（对比kafka）—旧文章搬运"><a href="#RocketMQ自学（对比kafka）—旧文章搬运" class="headerlink" title="RocketMQ自学（对比kafka）—旧文章搬运"></a>RocketMQ自学（对比kafka）—旧文章搬运</h1><p><a name="Sda4S"></a></p><h2 id="1-MQ"><a href="#1-MQ" class="headerlink" title="1. MQ"></a>1. MQ</h2><p>消息队列是解耦高并发系统所需要的一种组件（通常为分布式）。分布式保证自身的可用性，从而使得维护的时候可以专心，编写代码可以各司其职，提高整个系统的可靠性和吞吐量。<br><a name="ZT5qH"></a></p><h2 id="2-RocketMQ"><a href="#2-RocketMQ" class="headerlink" title="2. RocketMQ"></a>2. RocketMQ</h2><p><a name="uizTv"></a></p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>RocketMQ是阿里巴巴开源，apache旗下的一个MQ，他的可选模式多种多样，适合各种场景去使用。<br><a name="yyjxx"></a></p><h3 id="分布式架构"><a href="#分布式架构" class="headerlink" title="分布式架构"></a>分布式架构</h3><p><a name="UuHfR"></a></p><h4 id="RocketMQ分布式架构"><a href="#RocketMQ分布式架构" class="headerlink" title="RocketMQ分布式架构"></a>RocketMQ分布式架构</h4><p>RocketMQ的分布式架构挺有特点的，抛开nameserver，最关键的就是在broker的配置上,主要分为以下几种模式：</p><ol><li>单master，只有一个broker节点，可用性最低，且容易导致整个系统宕机。</li><li>多master，一个集群全为master，问题：当一台master挂掉时，在其上的信息队列会不可用。注意：写入磁盘的时候宕机可能会有丢失数据的风险。</li><li>多master多salve模式，每个master配置一个salve，做主从同步。但主从同步也有异步同步和同步同步的区别，要根据不同的场景去选择，有着不同的优缺点。注意，如果m-s对中，master挂掉时候生产者无法向该topic提交，但消费者可以消费。</li></ol><p>因为大部分MQ我们在使用的时候要注意的东西其实偏顶层，但分析一下分布式架构就可以在使用的时候更清楚。<br />这里我们用kafka的分布式架构来进行对比：<br><a name="SNQGc"></a></p><h4 id="kafka分布式架构对比"><a href="#kafka分布式架构对比" class="headerlink" title="kafka分布式架构对比"></a>kafka分布式架构对比</h4><p>kafka在broker和topic之间引入了一个partition的概念，这个partition有点RAID1的味道，但完全不一样，因为这个使用网络进行同步，所以会有延迟，因此为了追求数据的线性一致性，就舍弃了topic粒度下的负载均衡，让对同一个topic生产和消费都从leader partition中获取。<br />当然如果每个topic的内容差不多，这种是没问题的，但如果为了追求可用性，当单一topic会非常热门的话，就有可能成为性能瓶颈。<br />当然这种情况最适合的场景就是实时通信软件，message的生产和消费每一个topic都比较均衡。并且这种的有序的保证是最高的。<br />但RocketMQ也可以做对有序性要求比较高的场景，只要控制好使用同步的主从同步策略，就可以从理论上保证消息的有序性。<br><a name="ocBLj"></a></p><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><p>MQ作为一种中间件，本身就是为了解耦和突破吞吐瓶颈出现的存在的，因为配置不得当，可能会引入新的问题，所以还是要在合适的场景下选用合适的MQ用合适的架构方案去做这件事。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;RocketMQ自学（对比kafka）—旧文章搬运&quot;&gt;&lt;a href=&quot;#RocketMQ自学（对比kafka）—旧文章搬运&quot; class=&quot;headerlink&quot; title=&quot;RocketMQ自学（对比kafka）—旧文章搬运&quot;&gt;&lt;/a&gt;RocketMQ自学（</summary>
      
    
    
    
    
    <category term="软件工程" scheme="https://kairbon.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
</feed>
